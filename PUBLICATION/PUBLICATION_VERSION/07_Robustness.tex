\section{Robustness Checks and Potential Alternative Designs}
\label{sec: robustness}

In this section I will report and comment on some robustness checks that were performed. As a first examination, the main contribution of this thesis (the introduction of term weighting based on past volatility) will be tested against benchmark term weighting schemes. The second subsection deals with the question whether predictive performance can be improved when different volatility proxies are applied instead of \texttt{PFRV}. The third and final subsection seeks to test the robustness of the results as well as changes in the importance of 10-K* language for post-filing realized volatility when one uses more potent variables to replace pre-filing realized volatility: thus, instead of \texttt{PreFRV}, two time-series model forecasts ((GJR-) GARCH) will be used in the multivariate analysis.

% ----------------------------------------------------------- %

\subsection{Tests Against Conventional Benchmark Term-Weighting Schemes}
\label{ssec: robust_weightschemes}

As already indicated when presenting the definition of conventional weighting schemes, the benchmarks against which \texttt{VIBTW} shall be tested will be the following: term frequency-inverse document frequency (\texttt{TFIDF}), relative frequency-inverse document frequency (\texttt{RFIDF}), one plus log-weighted frequencies with and without inverse document frequency (\texttt{WF\_1PLOG} and \texttt{WFIDF\_1PLOG}, respectively), log-one-plus weighted frequencies with and without inverse document frequency (\texttt{WF\_LOG1P} and \texttt{WIFDF\_LOG1P}, respectively), and maximum-scaled term frequencies (\texttt{TFMAX}). 

Table \ref{tab: cormat_schemes} presents five correlation matrices, each representing the five textual variables (\texttt{NEG\_SENT}, \texttt{POS\_SENT}, \texttt{ASSERT}, \texttt{UNCERT}, and \texttt{LITI}) and each being of dimension eight by eight (i.e., one measure for each of the weighting schemes) and. It is evident from the Table that weighting schemes \texttt{WF\_1PLOG} (\texttt{WFIDF\_1PLOG}) and \texttt{WF\_LOG1P}  (\texttt{WIFDF\_LOG1P}) correlate (almost) perfectly; thus, it seems irrelevant whether the log-transform is applied on raw counts and then added to one or whether counts are increased by unity and then logged. With the exception of assertiveness in the language (variable \texttt{ASSERT}), the volatility-based weighting scheme correlates positively (and in virtually all cases significantly) with the other scores, although the absolute magnitude is rather small (below .30 in all cases). As for other descriptive statistics involving \texttt{VIBTW}, the estimations are based on the full sample of 46,483 annual filings. Moreover, those scores that take account of inverse document frequency correlate heavier among each other compared to correlations with the log/max-weighted term frequencies; the latter, in turn, correlate among each other more intensely.

These observations give rise to estimate the linear model in \eqref{eq: linear_reg} with alternative weighting schemes so as to benchmark market-impact-based weighting against established, conventional methods. In order to ensure presentability, regressions were estimated in a pooled OLS model for years 2013-2017 for all eight weighting schemes\footnote{Therefore, both \texttt{VIBTW} and IDF-weights were estimated from 10-K* filings from 1999 to 2012.}. The results are shown in Table \ref{tab: C_MZ_regression_pooled}. In general, there is no large difference in goodness-of-fit, yet the \texttt{VIBTW} scheme delivers the best performance. Speaking additionally in favour of volatility-based term weighting is the relative economic size of the estimated coefficients, which besides statistical significance implies that the appearance of words that co-occurred with high volatility in the past is likely to induce higher post-10-K*-filing realized volatility as well. Surprisingly, and indicating that weights on the basis of market reaction seem to smooth out the importance compared to other weighting designs, assertive language (\texttt{ASSERT}) is highly significant for the \texttt{WF\_1PLOG} and \texttt{WF\_LOG1P}  schemes, respectively. The same argument holds true for the focus on financial topics (\texttt{FIN}) and the \texttt{TFMAX} weighting scheme. Another interesting fact that is revealed by Table \ref{tab: C_MZ_regression_pooled} is that log-transformed (IDF) term weights disagree with the \texttt{VIBTW} scheme when it comes to the impact uncertain language in a 10-K* has on \texttt{PFRV}. While past-volatility-based weighting leads to a (expected) significant positive relation for \texttt{LITI}, columns (4) to (7) surprisingly indicate that language of uncertainty \textit{decreases} post-filing realized volatility. Concerning the control variables, it is worth mentioning that -- irrespective of the word weighting scheme applied in the textual analysis part -- all results are significant and with expected sign. This is especially noteworthy for the level of market calmness/turbulence (measured by the level of the VIX), which displayed ambiguous results in the annual cross-sectional regressions. 

% ----------------------------------------------------------- %

\subsection{Alternative Volatility Proxies}
\label{ssec: robust_alternative-vola-proxies}
The second robustness check applied in this thesis relates to the left-hand side in both weight regressions and the augmented MZ-regression, and is thus connected with the measurement of post-filing volatility. As indicated in section \ref{ssec: senti_LHS}, in this thesis a measure of weekly \textit{realized} volatility was applied. Two commonly regarded alternative volatility proxies are squared returns (\texttt{PFSqR})and absolute returns (\texttt{PFAbsR}). However, the regression results do not seem to be driven by measurement error in the dependent variable: as Table \ref{tab: COR_VOLAS}, which was presented in the section on results, indicates, the two alternative volatility measures correlate almost one-for-one with the realized volatility variable \texttt{PFRV} (correlation coefficients of .98 for \texttt{PFSqR} and .97 for \texttt{PFAbsR}, respectively). 
%This holds true for original values as well as log-transformed proxies, with all Pearson correlation coefficients in the matrix being highly significant ($p < .001$). 

Based on this strong similarity between the different measures, one does not expect perceptible changes when testing the models against alternative proxies of volatility. To examine the effect of how the volatility variable is computed, I estimated pooled regressions of the linear model in equation \eqref{eq: linear_reg} with \texttt{VIBTW} weights coming from 1999-2012 for the two chosen alternative specifications, using either squared or absolute returns as surrogate proxies. The results of these two pooled regressions are displayed in Table \ref{tab: robust_new_sq_abs}. Probably attributable to the usage of \enquote{noisier} post-filing volatility proxies, the overall goodness of fit measured by the model's R-squared is about five percentage points higher compared to the realized volatility approach. This manifests also in the jump of the size of $\beta_1$, the coefficient attributed to \texttt{PreFRV}, which increases from .039 in the realized volatility model to .299  for squared returns and .294 for absolute returns, respectively. The main findings related to 10-K* language are hardly distinguishable from the pooled regression using realized volatility, i.e., mainly negative and positive sentiment affect post-filing volatility. As for the model using \texttt{PFRV}, litigious language is also significant when using the pooled regression approach, whereas it was only relevant for several years when tested in the annual regression framework. Moreover, resembling prior results, the usage of \texttt{PFSqR} and \texttt{PFAbsR} does not alter the importance of textual assertiveness, readability and the degree of financial keywords; all of them are insignificant in providing incremental explanatory power. The appearance of uncertain language, however, is significant on ten percent level and increases post-filing volatility, if the latter is measured by squared or absolute returns in the week after the 10-K* submission. Finally, all estimates related to the control variables are almost identical to the ones obtained using the proxy \texttt{PFRV} (implying significance and expected sign in both specifications).

% ----------------------------------------------------------- %

\subsection{Substituting Pre-Filing Realized Volatility with Time-Series Inputs}
\label{ssec: robust_prefiling}
The third and last robustness check to be performed concerns the replacement of the variable \texttt{PreFRV} with more powerful predictors of firm-specific volatility. Instead of using simply the \enquote{past observation}, i.e., pre-filing realized volatility, as a linear input in a regression framework, I will use 1-week ahead forecasts from two widely-used time-series models as predictors. The models of choice are the GARCH and GJR-GARCH\footnote{The main motivation for the choice of these two models is to have both one symmetric and one asymmetric model; GARCH(1,1) and GJR-GARCH(1,1) have proven to be parsimonious yet effective and hard-to-beat benchmarks (e.g., also considered in \textcite{AntweilerFrank2004} and \textcite{HansenLunde}).}. The corresponding models that were used to produce 1-week ahead forecasts were estimated on weekly return data from one year prior to the filing date (or, alternatively, the maximum number of weekly data available, if this number is smaller than 52). The two time-series models shall be used in order to test the idea whether a much more potent predictor still leaves room for volatility to be explained by quantitative information contained in the 10-K* filing, and, thus, affects the significance of the text-related variables. The latter notion stems from the idea that -- compared to \texttt{PreFRV} -- the forecasts from (GJR-) GARCH might \enquote{absorb} the most variation in \texttt{PFRV}, thereby leaving little room for sentiment variables to improve the model's performance. 

The robustness check can be performed in eight variants (two pooled out-of-sample OLS regressions with static training window for both the GARCH- as well as the GJR-GARCH-model, or,  alternatively, annual regressions using static/rolling/extending weight training windows for both GARCH and the GJR-GARCH). The regression results for the pooled regressions are presented in Tables \ref{tab: A_MZ_regression_garch} and \ref{tab: A_MZ_regression_gjr}. For the pooled regressions, the goodness-of-fit of the models is generally higher (about 8 percentage points larger R-Squared compared to the baseline that used pre-filing realized volatility). This is true for all specifications of weighting scheme. With respect to the textual variables within the \texttt{VIBTW} methodology (displayed in the first column of Tables \ref{tab: A_MZ_regression_garch} and \ref{tab: A_MZ_regression_gjr}), the regressions using (GJR-)GARCH partly confirm the conjecture that potent time-series models \enquote{soak up} the variation in \texttt{PFRV}. While both negative and positive tonality in the annual report remain significant, litigious language (\texttt{LITI}) is not (less) significant when using the GARCH (GJR-GARCH) inputs.

The annual MZ regressions presented in Tables \ref{tab: B1_MZ_garch} through \ref{tab: B2_MZ_gjr} also in part confirm the idea of an significance \enquote{absorption} by the two powerful time-series models: considering that there are 35 coefficients of particular interest for each of the models (seven textual variables times five out-of-sample years), the baseline model using pre-filing realized volatility \enquote{relies} heavier on the textual inputs, with the number of significant entries out of the 35 possible in all cases exceeding those of the (GJR-) GARCH based estimators, with the exception of the rolling training window. Table \ref{tab: SSS} summarizes the number of significant textual variables for each of the models and training set methodologies (static, rolling, and extending) presented in this chapter.

%\input{./Results_Tables/robustness_sq_abs_regressions}

% ---------------------- NEW ---------------------- %
\subsection{Adding 10-K* Related Quantitative Control Variables}
\label{ssec: robust_publi_quantcontrolvars}

The last and most important robustness check concerns the isolation of textual content in the 10-K* from the simultaneous release of quantitative information contained therein. To illustrate this point, one can think of the following example: the fact that the filing company uses the (negatively connoted) word \textsf{loss} might per se \textbf{not} be driving volatility at all -- and any impact from a negative sentiment score in such a case might be instead fully attributable to the fact that the company reported a loss in the first place, which is negative news for investors on its own. Hence, 10-K* language might be used merely to describe, accentuate, support, or alleviate the quantitative results of the fiscal year, without providing value added above any of the metrics reported in the same filing. Thus, controlling for the simultaneous release of investor-relevant metrics is necessary. A good orientation for this task is again \textcite{Feldman_et_al_2010}, who controlled for simultaneous earnings, accruals, and cash-flow-based measures to isolate the effect of sentiment in the domain for equity returns. 

Using data from Compustat (WRDS), I opted to include the following 10-K* related quantitative information:

\begin{itemize}
\item P\&L turnaround (\texttt{PnL\_TURN}): boolean that indicates if a company has managed to turn around a loss into a profit (or maintain a profit) between two consecutive filings
\item Balance sheet growth (\texttt{SIZE\_CHG}): relative change in total assets between two consecutive filings
\item Change in book-to-market ratio between two consecutive filings (\texttt{BTM\_CHG})
\item Relative change in the leverage ratio between two consecutive filings (\texttt{LEVER\_CHG})
\item Sales growth (\texttt{SALES\_GROWTH}): relative change in revenues between two consecutive filings
\item Share buyback (\texttt{SHR\_BUYBACK}): boolean that indicates whether the number of shares outstanding has been reduced between two consecutive filings
\item Change in profitability (\texttt{PROF\_CHG}): relative change in the profit margin
%(alternatively: EBIT/Sales or EBITDA/Sales)
\end{itemize}

Note that two filings are considered to be \enquote{consecutive} if their filing year is not more than two years apart. Moreover, due to missing information for some entities, adding these variables reduces the size of the test set to 11,759 filings (previously: 13,679).

In addition to the seven variables presented above, I included two interaction variables: positive sentiment times P\&L turnaround, labelled \texttt{POS\_SENTxPnL}, and positive sentiment times change in profitability, labelled \texttt{POS\_SENTxPROF\_CHG}. These variables aim to control for a potential usage of false positive language. The idea is that firms might make excessive use of positive sentiment words whenever they have to convey negative news to investors (this could be either because they accentuate other positive things more heavily, or, use negation constructs like \textsf{not increased} to in fact describe \textsf{decreased}). 

The results of the extended models is displayed in Tables \ref{tab: publication_annual_regressions_static} through \ref{tab: publication_pooled}. Table \ref{tab: publication_pooled} displays the estimation in a pooled OLS setting, and - in comparison with \ref{tab: C_MZ_regression_pooled} - shows that negative, positive and litigious language remain significant even after the introduction of the 10-K* related metrics. Similarly, firm size and leverage, book-to-market ratio, the level of the VIX and the trading volume are still significant predictors of \texttt{PFRV} when the additional quantitative control variables are included in the model. With respect to the newly variables it is worth noting that only the share buyback indicator and the change in leverage are significant on levels of 99 percent and 95 percent of confidence, respectively. The overall fit of the extended model is about four percentage points higher than in the standard version (R-Squared of 36.6\% compared to 32.8\%). However, inspecting Tables \ref{tab: publication_annual_regressions_static}, \ref{tab: publication_annual_regressions_rolling}, and \ref{tab: publication_annual_regressions_extending} one can observe that the effect of including quantitative metrics is heterogeneous across years and model specification in terms of weight estimation method (static / rolling / extending). While in some cases the metric-effect seems to drive out the language-effect, in other constellations text-related variables become (or in most cases: remain) significant.

One last remark shall be made on the data used to construct the control variables. All figures are computed from balance sheet and profit-and-loss statements from the Compustat database and are always chosen to come from the end of year before the 10-K* was filed. In most cases these figures are filled/corrected in retrospective (for instance, the download of the revenues for a illustrative company X might read 50 million USD as per year-end 2017, i.e., 31/12/2017. However, very often this figure is revealed in the 10-K* filing released in, say, March 2018, and then retroactively filled to match the financial year 2017). As the subject of analysis in this work are 10-K* filings and these are released annually (with the exception of amendments), for all cases where the fundamental data for the previous financial year is available, these figures should therefore coincide with the metrics reported in the filing itself. 

\clearpage