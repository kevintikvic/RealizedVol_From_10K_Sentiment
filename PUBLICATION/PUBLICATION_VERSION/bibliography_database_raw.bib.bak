% Encoding: UTF-8

@Article{HuangZangZheng14,
  author        = {Huang, Allen H. and Zang, Amy Y. and Zheng, Rong},
  title         = {Evidence on the Information Content of Text in Analyst Reports},
  year          = {2014},
  volume        = {89},
  number        = {6},
  pages         = {2151-2180},
  __markedentry = {[kevintikvic:5]},
  abstract      = {We document that textual discussions in a sample of 363,952 analyst reports provide information to investors beyond that in the contemporaneously released earnings forecasts, stock recommendations, and target prices, and also assist investors in interpreting these signals. Cross-sectionally, we find that investors react more strongly to negative than to positive text, suggesting that analysts are especially important in propagating bad news. Additional evidence indicates that analyst report text is more useful when it places more emphasis on nonfinancial topics, is written more assertively and concisely, and when the perceived validity of other information signals in the same report is low. Finally, analyst report text is shown to have predictive value for future earnings growth in the subsequent five years.},
  file          = {:C\:\\Users\\User\\Dropbox\\Master_Thesis\\Text_mining_literature\\HuangZangZheng.pdf:PDF},
  journal       = {The Accounting Review},
}

@PhdThesis{Qiu07,
  author      = {Qiu, Xin Ying},
  title       = {On building predictive models with company annual reports},
  institution = {University of Iowa},
  year        = {2007},
  type        = {phdthesis},
  abstract    = {Text mining and machine learning methodologies have been applied to biomedicine and business domains for new relationship and knowledge discovery. Company annual reports (or 10K filings), as one of the most important mandatory information disclosures, have remained untapped by the text mining and machine learning community. Previous research indicates that the narrative disclosures in company annual reports can be used to assess the company’s short-term financial prospects. In this study, we apply text classification methods to 10K filings to systematically assess the predictive potential of company annual reports. We specify our research problem along five dimensions: financial performance indicators, choice of predictions, evaluation criteria, document representation, and experiment design. Different combinations of the choices we made along the five dimensions provide us with different perspectives and insights into the feasibility of using annual reports to predict company future performance. Our results confirm that predictive models can be successfully built using the textual content of annual reports. Mock portfolios constructed with firms predicted by the text-based model are shown to produce positive average stock return. Sub-sample experiments and post-hoc analysis further confirm that the text-based model is able to catch the textual differences among firms with different financial characteristics. We see a rich set of research questions with the promise of further insight in this research area.},
  file        = {:C\:\\Users\\User\\Dropbox\\Master_Thesis\\Text_mining_literature\\Qiu_PhDThesis.pdf:PDF},
  school      = {University of Iowa},
}

@InProceedings{Kogan2009_1,
  author        = {Kogan, Shimon and Levin, Dimitry and Routledge, Bryan R. and Sagi, Jacob S. and Smith, Noah A.},
  title         = {Predicting Risk from Financial Reports with Regression},
  booktitle     = {Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  year          = {2009},
  publisher     = {Association for Computational Linguistics},
  pages         = {272--280},
  __markedentry = {[kevin:5]},
  abstract      = {We address a text regression problem: given a piece of text, predict a real-world continuous quantity associated with the text’s meaning. In this work, the text is an SEC-mandated financial report published annually by a publicly-traded company, and the quantity to be predicted is volatility of stock returns, an empirical measure of financial risk. We apply well-known regression techniques to a large cor- pus of freely available financial reports, constructing regression models of volatility for the period following a report. Our models rival past volatility (a strong baseline) in predicting the target variable, and a single model that uses both can significantly outperform past volatility. Interestingly, our approach is more accurate for reports after the passage of the Sarbanes-Oxley Act of 2002, giving some evidence for the success of that legislation in making financial reports more informative.},
  address       = {Stroudsburg, USA},
  file          = {:C\:\\Users\\User\\Dropbox\\Master_Thesis\\Text_mining_literature\\KoganLevinRoutledgeSagiSmith.pdf:PDF},
  numpages      = {9},
}

@Article{LussDAspremont2012,
  author        = {Luss, Ronny and D’Aspremont, Alexandre},
  title         = {Predicting abnormal returns from news using text classification},
  journal       = {Quantitative Finance},
  year          = {2012},
  pages         = {1-14},
  __markedentry = {[kevin:2]},
  abstract      = {We show how text from news articles can be used to predict intraday price movements of financial assets using support vector machines. Multiple kernel learning is used to combine equity returns with text as predictive features to increase classification performance and we develop an analytic center cutting plane method to solve the kernel learning problem efficiently. We observe that while the direction of returns is not predictable using either text or returns, their size is, with text features producing significantly better performance than historical returns alone.},
  file          = {:C\:\\Users\\User\\Dropbox\\Master_Thesis\\Text_mining_literature\\luss2015.pdf:PDF},
}

@InProceedings{Rekabsaz2017,
  author        = {Rekabsaz, Navid and Lupu, Mihai and Baklanov, Artem and Hanbury, Allan and Duer, Alexander and Anderson, Linda},
  title         = {Volatility Prediction using Financial Disclosures Sentiments with Word Embedding-based IR Models},
  booktitle     = {Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2017)},
  year          = {2017},
  location      = {Vancouver, Canada},
  pages         = {1712-1721},
  __markedentry = {[kevin:5]},
  abstract      = {Volatility prediction—an essential concept in financial markets—has recently been addressed using sentiment analysis methods. We investigate the sentiment of annual disclosures of companies in stock markets to forecast volatility. We specifically explore the use of recent Information Retrieval (IR) term weighting models that are effectively extended by related terms using word embeddings. In parallel to textual information, factual market data have been widely used as the mainstream approach to forecast market risk. We therefore study different fusion methods to combine text and market data resources. Our word embedding-based approach significantly outperforms state-of- the-art methods. In addition, we investigate the characteristics of the reports of the companies in different financial sectors.},
  file          = {:C\:\\Users\\User\\Dropbox\\Master_Thesis\\Text_mining_literature\\Rekabsaz-Volatility_Prediction_using_Financial_Disclosures_.pdf:PDF},
}

@Article{Li2010,
  author        = {Li, Feng},
  title         = {The Information Content of Forward-Looking Statements in Corporate Filings—A Naïve Bayesian Machine Learning Approach},
  journal       = {Journal of Accounting Research},
  year          = {2010},
  volume        = {48},
  number        = {5},
  pages         = {1049--1102},
  issn          = {1475-679X},
  __markedentry = {[kevin:5]},
  abstract      = {This paper examines the information content of the forward-looking statements (FLS) in the Management Discussion and Analysis section (MD&A) of 10-K and 10-Q filings using a Naïve Bayesian machine learning algorithm. I find that firms with better current performance, lower accruals, smaller size, lower market-to-book ratio, less return volatility, lower MD&A Fog index, and longer history tend to have more positive FLSs. The average tone of the FLS is positively associated with future earnings even after controlling for other determinants of future performance. The results also show that, despite increased regulations aimed at strengthening MD&A disclosures, there is no systematic change in the information content of MD&As over time. In addition, the tone in MD&As seems to mitigate the mispricing of accruals. When managers “warn” about the future performance implications of accruals (i.e., the MD&A tone is positive (negative) when accruals are negative (positive)), accruals are not associated with future returns. The tone measures based on three commonly used dictionaries (Diction, General Inquirer, and the Linguistic Inquiry and Word Count) do not positively predict future performance. This result suggests that these dictionaries might not work well for analyzing corporate filings.},
  file          = {:C\:\\Users\\User\\Dropbox\\Master_Thesis\\Text_mining_literature\\Li2010.pdf:PDF},
}

@Article{Kalev2004,
  author        = {Kalev, Petko S. and Liu, Wai-Man and Pham, Peter K. and Jarnecic, Elvis},
  title         = {Public information arrival and volatility of intraday stock returns},
  year          = {2004},
  volume        = {28},
  number        = {6},
  pages         = {1441 - 1467},
  issn          = {0378-4266},
  __markedentry = {[kevintikvic:5]},
  abstract      = {This study employs firm-specific announcements as a proxy for information flows and investigates the information–volatility relation using high-frequency data from the Australian Stock Exchange. Our analysis reveals a positive and significant impact of the arrival rate of the selected news variable on the conditional variance of stock returns, even after controlling for the potential effects of trading volume and high opening volatility. Furthermore, the inclusion of the news variable in the conditional variance equation of the generalized autoregressive conditional heteroscedastic model also reduces volatility persistence, especially with intraday data. Combined with the evidence that news arrivals display a very strong pattern of autocorrelation, our results are consistent with the Mixture of Distribution Hypothesis, which attributes conditional heteroscedasticity of stock returns to time-dependence in the news arrival process.},
  file          = {:kalev2004.pdf:PDF},
  journal       = {Journal of Banking \& Finance},
  keywords      = {ARCH, Public information arrival, Mixture of distribution hypothesis, Trading volume, Volatility persistence},
}

@MastersThesis{Cassidy-Thesis-2015,
  author        = {Cassidy, Caitlyn},
  title         = {Between the hedges: A Computational Analysis of Sentiment and Linguistic Hedging in Financial Documents},
  institution   = {University of Georgia},
  year          = {2015},
  type          = {mathesis},
  __markedentry = {[kevin:4]},
  abstract      = {Each year, publicly incorporated companies are required to file a Form 10-K with the United States Securities and Exchange Commission. These documents contain an enormous amount of natural language data and may offer insight into financial performance prediction. This thesis attempts to analyze two dimensions of language held within this data: sentiment and linguistic hedging. An experiment was conducted with 325 human annotators to manually score a subset of the sentiment words contained in a corpus of 106 10-K filings, and an inference engine identified instances of hedges having governance over these words in a dependency tree. Finally, this work proposes an algorithm for the automatic classification of sentences in the financial domain as speculative or non-speculative using the previously defined hedge cues.},
  file          = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/Cassidy_Thesis2015.pdf:PDF},
}

@Article{Cao2001,
  author   = {Cao, Lijuan and Tay, Francis E. H.},
  title    = {Financial Forecasting Using Support Vector Machines},
  journal  = {Neural Computing {\&} Applications},
  year     = {2001},
  volume   = {10},
  number   = {2},
  month    = {May},
  pages    = {184--192},
  issn     = {1433-3058},
  abstract = {The use of Support Vector Machines (SVMs) is studied in financial forecasting by comparing it with a multi-layer perceptron trained by the Back Propagation (BP) algorithm. SVMs forecast better than BP based on the criteria of Normalised Mean Square Error (NMSE), Mean Absolute Error (MAE), Directional Symmetry (DS), Correct Up (CP) trend and Correct Down (CD) trend. S&P 500 daily price index is used as the data set. Since there is no structured way to choose the free parameters of SVMs, the generalisation error with respect to the free parameters of SVMs is investigated in this experiment. As illustrated in the experiment, they have little impact on the solution. Analysis of the experimental results demonstrates that it is advantageous to apply SVMs to forecast the financial time series.},
  file     = {:Cao2001.pdf:PDF},
  keywords = {Back propagation algorithm; Financial time series forecasting; Generalisation; Multi-layer perception; Support vector machines},
}

@InProceedings{Robertson2007,
  author    = {Robertson, Calum S. and Geva, Shlomo and Wolff, Rodney C.},
  title     = {News Aware Volatility Forecasting: Is the Content of News Important?},
  booktitle = {Proceedings of the Sixth Australasian Conference on Data Mining and Analytics},
  year      = {2007},
  volume    = {70},
  series    = {AusDM '07},
  pages     = {161--170},
  address   = {Darlinghurst, Australia, Australia},
  month     = dec,
  publisher = {Australian Computer Society, Inc.},
  abstract  = {The efficient market hypothesis states that the market incorporates all available information to provide an accurate valuation of the asset at any given time. However, most models for forecasting the return or volatility of assets completely disregard the arrival of asset specific news (i.e., news which is directly relevant to the asset). In this paper we propose a simple adaptation to the GARCH model to make the model aware of news. We propose that the content of news is important and therefore describe a methodology to classify asset specific news based on the content. We present evidence from the US, UK and Australian markets which show that this model improves high frequency volatility forecasts. This is most evident for news which has been classified based on the content. We conclude that it is not enough to know when news is released, it is necessary to interpret its content.},
  file      = {:Robertson2007.pdf:PDF},
  isbn      = {978-1-920682-51-4},
  keywords  = {document classification, forecast, news, stock market, volatility},
  location  = {Gold Coast, Australia},
  numpages  = {10},
}

@Article{Das2014,
  author   = {Das, Sanjiv R.},
  title    = {Text and Context: Language Analytics in Finance},
  journal  = {Foundations and Trends® in Finance},
  year     = {2014},
  volume   = {8},
  number   = {3},
  pages    = {145-261},
  issn     = {1567-2395},
  abstract = {This monograph surveys the technology and empirics of text analytics in finance. I present various tools of information extraction and basic text analytics. I survey a range of techniques of classification and predictive analytics, and metrics used to assess the performance of text analytics algorithms. I then review the literature on text mining and predictive analytics in finance, and its connection to networks, covering a wide range of text sources such as blogs, news, web posts, corporate filings, etc. I end with textual content presenting forecasts and predictions about future directions.},
  file     = {:Das2014.pdf:PDF;:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/Das2014_orig.pdf:PDF},
}

@InBook{Achananuparp2008,
  pages     = {305-316},
  title     = {The Evaluation of Sentence Similarity Measures},
  publisher = {Springer Berlin Heidelberg},
  year      = {2008},
  author    = {Achananuparp, Palakorn and Hu, Xiaohua and Shen, Xiajiong},
  editor    = {Song, Il-Yeol and Eder, Johann and Nguyen, Tho Manh},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-540-85836-2},
  abstract  = {The ability to accurately judge the similarity between natural language sentences is critical to the performance of several applications such as text mining, question answering, and text summarization. Given two sentences, an effective similarity measure should be able to determine whether the sentences are semantically equivalent or not, taking into account the variability of natural language expression. That is, the correct similarity judgment should be made even if the sentences do not share similar surface form. In this work, we evaluate fourteen existing text similarity measures which have been used to calculate similarity score between sentences in many text applications. The evaluation is conducted on three different data sets, TREC9 question variants, Microsoft Research paraphrase corpus, and the third recognizing textual entailment data set.},
  booktitle = {Data Warehousing and Knowledge Discovery: 10th International Conference, DaWaK 2008 Turin, Italy, September 2-5, 2008 Proceedings},
  file      = {:Achananuparp2008.pdf:PDF},
}

@Article{GavrishchakaGanguli2003,
  author        = {Gavrishchaka, Valeriy V. and Ganguli, Supriya B.},
  title         = {Volatility forecasting from multiscale and high-dimensional market data},
  year          = {2003},
  volume        = {55},
  number        = {1},
  pages         = {285 - 305},
  issn          = {0925-2312},
  __markedentry = {[kevintikvic:3]},
  abstract      = {Advantages and limitations of the existing volatility models for forecasting foreign-exchange and stock market volatility from multiscale and high-dimensional data have been identified. Support vector machines (SVM) have been proposed as a complimentary volatility model that is capable of effectively extracting information from multiscale and high-dimensional market data. SVM-based models can handle both long memory and multiscale effects of inhomogeneous markets without restrictive assumptions and approximations required by other models. Preliminary results with foreign-exchange data suggest that SVM can effectively work with high-dimensional inputs to account for volatility long-memory and multiscale effects. Advantages of the SVM-based models are expected to be of the utmost importance in the emerging field of high-frequency finance and in multivariate models for portfolio risk management.},
  file          = {:gavrishchaka2003.pdf:PDF},
  journal       = {Neurocomputing},
  keywords      = {Volatility models, Support vector machines, High-frequency finance},
}

@Article{Schutte2007,
  author        = {Schutte, Maria G. and Unlu, Emre},
  title         = {The Effect of Analyst Coverage on Firm-Specific Volatility: Less Information or Less Noise?},
  journal       = {Financial Analyst Journal},
  year          = {2007},
  __markedentry = {[kevin:1]},
  abstract      = {We look at whether the negative relation between firm-specific volatility and analyst coverage occurs because analysts reduce firm-specific information or whether they reduce noise. We hypothesize that analyst research helps investors discern between information signals and noisy signals. As a result, fewer noisy signals are misinterpreted for information, resulting in less noise in price fluctuations. We study the effects of analyst coverage on firm-specific volatility in US analyst coverage initiations between 1984 and 2002. We find a significant reduction in noise after analyst initiations that cannot be explained by firm growth, increase in trading volume, or increase in institutional ownership. Additionally, the magnitude of the increase in coverage has a direct effect on the magnitude of the noise reduction after initiations.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/Schutte2007.pdf:PDF},
  keywords      = {Noise; Analysts; Idiosyncratic Volatility},
}

@Article{Winchel2015,
  author        = {Winchel, Jennifer},
  title         = {Investor Reaction to the Ambiguity and Mix of Positive and Negative Argumentation in Favorable Analyst Reports},
  journal       = {Contemporary Accounting Research},
  year          = {2015},
  volume        = {32},
  number        = {3},
  issn          = {1911-3846},
  __markedentry = {[kevin:1]},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/Winchel2015.pdf:PDF},
}

@Article{Loughran2014,
  author        = {Loughran, Tim and McDonald, Bill},
  title         = {Measuring Readability in Financial Disclosures},
  journal       = {The Journal of Finance},
  year          = {2014},
  volume        = {69},
  number        = {4},
  pages         = {1643--1671},
  issn          = {1540-6261},
  doi           = {10.1111/jofi.12162},
  url           = {http://dx.doi.org/10.1111/jofi.12162},
  __markedentry = {[kevin:4]},
  abstract      = {Defining and measuring readability in the context of financial disclosures becomes important with the increasing use of textual analysis and the Securities and Exchange Commission’s plain English initiative. We propose defining readability as the effective communication of valuation-relevant information. The Fog Index—the most commonly applied readability measure—is shown to be poorly specified in financial applications. Of Fog’s two components, one is misspecified and the other is difficult to measure. We report that 10-K document file size provides a simple readability proxy that outperforms the Fog Index, does not require document parsing, facilitates replication, and is correlated with alternative readability constructs.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/Loughran2014.pdf:PDF},
}

@Unpublished{HerrmannKerl2015,
  author        = {Herrmann, Leonie and Kerl, Alexander G.},
  title         = {What makes an analyst report influential?},
  year          = {2015},
  note          = {Working Paper, available under \url{http://dx.doi.org/10.2139/ssrn.2647266} (visited on 08/01/2018)},
  url           = {http://dx.doi.org/10.2139/ssrn.2647266},
  urldate       = {2018-08-01},
  __markedentry = {[kevin:1]},
  abstract      = {This paper examines common analyst report characteristics that make it likely for a report to significantly influence stock prices. First, a measurable market impact is positively associated with the size of the change in recommendations, earnings forecasts and target prices. Second, analyst-specific characteristics are decisive (i.e. consensus proximity, gender, workload and the time of publication). Third, on the firm-level, a report about a high-attention company with a high price-to-book value, small size and high turnover is more likely to be influential.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/HerrmanKerl2015.pdf:PDF},
  keywords      = {analyst report, stock recommendation, earnings forecast, price target, influential forecast},
}

@Article{BrownleesEngleKelly2011,
  author        = {Brownlees, Christian and Engle, Robert F. and Kelly, Bryan T.},
  title         = {A Practical Guide to Volatility Forecasting through Calm and Storm},
  journal       = {Journal of Risk},
  year          = {2011},
  volume        = {14},
  number        = {2},
  month         = {Aug},
  pages         = {3-22},
  doi           = {10.21314/JOR.2012.237},
  __markedentry = {[kevin:2]},
  abstract      = {We present a volatility forecasting comparative study within the ARCH class of models. Our goal is to identify successful predictive models over multiple horizons and to investigate how predictive ability is influenced by choices for estimation window length, innovation distribution, and frequency of parameter re-estimation. Test assets include a range of domestic and international equity indices and exchange rates. We find that model rankings are insensitive to forecast horizon and suggestions for estimation best practices emerge. While our main sample spans 1990-2008, we take advantage of the near-record surge in volatility during the last half of 2008 to ask if forecasting models or best practices break down during periods of turmoil. Surprisingly, we find that volatility during the 2008 crisis was well approximated by predictions one-day ahead, and should have been within risk managers' 1% confidence intervals up to one month ahead.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/BrownleesEngleKelly2011.pdf:PDF},
}

@Online{SEC,
  author  = {{United States Securities and Exchange Commission (SEC)}},
  title   = {How to Read a 10-K},
  year    = {2011},
  date    = {2011-07-11},
  url     = {https://www.sec.gov/fast-answers/answersreada10khtm.html},
  urldate = {2018-05-27},
}

@Article{DeFranco2015,
  author       = {De Franco, Gus and Hope, Ole-Kristian and Vyas, Dushyantkumar and Zhou, Yibin},
  title        = {Analyst Report Readability},
  journaltitle = {Contemporary Accounting Research},
  year         = {2015},
  volume       = {32},
  number       = {1},
  pages        = {76-104},
  issn         = {1911-3846},
  doi          = {10.1111/1911-3846.12062},
  url          = {http://dx.doi.org/10.1111/1911-3846.12062},
  abstract     = {Using an extensive database of 356,463 sell-side equity analysts' reports from 2002 to 2009, this study is one of the first to analyze the readability of analysts' reports. We first examine the determinants of variations in analyst report readability. Using several proxies for ability, we show that reports are more readable when issued by analysts with higher ability. Second, we test the relation between analysts' report readability and stock trading volume reactions. We find that trading volume reactions increase with the readability of analysts' text, consistent with theoretical models that predict that more precise information (and hence more informative signals) results in investors' initiating trades. These results support the view that the readability of analysts' reports is important to analysts and capital market participants.},
  file         = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/DeFranco2015.pdf:PDF},
}

@Article{Asquith2005,
  author        = {Asquith, Paul and Mikhail, Michael B. and Au, Andrea S.},
  title         = {Information content of equity analyst reports},
  journal       = {Journal of Financial Economics},
  year          = {2005},
  volume        = {75},
  number        = {2},
  pages         = {245-282},
  url           = {https://doi.org/10.1016/j.jfineco.2004.01.002},
  __markedentry = {[kevin:1]},
  abstract      = {We catalog the complete contents of Institutional Investor All-American analyst reports and examine the market reaction to their release. Including the justifications supporting an analyst's opinion reduces, and in some models eliminates, the significance of earnings forecasts and recommendation revisions. Analysts both provide new information and interpret previously released information. The information in a report is most important for downgrades; target prices and the analyst's justifications are the only significant elements for reiterations. No correlation exists between valuation methodology and either analyst accuracy or the market's reaction to a report. Our adjusted R2s are much larger than those of studies using only summary measures.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/Asquith2005.pdf:PDF},
  keywords      = {Stock recommendations; Price targets; Earnings forecasts; Security analysts},
}

@Article{Stefan2016,
  author        = {Stefan, Matthias},
  title         = {On the impact of semantic framing in experimental asset markets},
  journal       = {Journal of Behavioral and Experimental Finance},
  year          = {2016},
  volume        = {9},
  pages         = {81-87},
  url           = {https://EconPapers.repec.org/RePEc:eee:beexfi:v:9:y:2016:i:c:p:81-87},
  __markedentry = {[kevin:1]},
  abstract      = {This paper studies how semantic framing affects price efficiency. In an experimental asset market subjects are provided with an overly positive, overly negative or no description of the asset traded. This description provides no information about the asset’s value. Prices are neither lower when subjects are negatively framed nor higher when subjects are positively framed compared to a treatment without framing. Furthermore, learning effects and price dynamics are comparable across treatments. I discuss two possible explanations from individual choice experiments, namely, that completely described problems and ratings and judgments are less prone to framing. Furthermore, I discuss an alternative possible explanation that asset markets are able to prevent biases to occur.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/Stefan2016.pdf:PDF},
  keywords      = {Experimental finance; Framing; Semantic information; Price efficiency; Asset markets},
}

@Article{HsiehHuiZhang2016,
  author       = {Hsieh, Chia C. and Hui, Kai W. and Zhang, Yao},
  title        = {Analyst Report Readability, Earnings Uncertainty and Stock Returns},
  journaltitle = {Journal of Business Finance \& Accounting},
  year         = {2016},
  volume       = {43},
  issue        = {1},
  pages        = {98--130},
  url          = {http://dx.doi.org/10.2139/ssrn.2182422},
  urldate      = {2017-10-22},
  abstract     = {This study investigates the association among readability of analyst reports, stock prices, and expectations of future earnings. Readability is one important feature of analyst reports that may affect value-relevant information. We find that analyst report readability reduces forecast dispersion but is not associated with revision news, and that market reactions are significantly positive towards more readable reports. In addition, we document that the market reacts positively to the reduction of forecast dispersion predicted by report readability. Finally, the positive effect of readability on stock prices is higher when it effectively reduces investors’ costs to process analyst report information, specifically when forecasting firms have more R&D spending, when transaction costs are higher, when analysts are more experienced, or when forecasts are issued after earnings announcements. Overall, our empirical findings suggest that the writing of analysts’ reports reduces uncertainty about future earnings, and investors price that reduction of uncertainty. This contributes to the understanding of the role of analysts as information intermediaries for investors.},
  file         = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/HsiehHuiZhang2016.pdf:PDF},
  keywords     = {Readability, Analyst Report, Earnings Uncertainty, Stock Returns},
}

@Article{Engle2001,
  author        = {Engle, Robert F.},
  title         = {GARCH 101: The Use of ARCH/GARCH Models in Applied Econometrics},
  journal       = {Journal of Economic Perspectives},
  year          = {2001},
  volume        = {15},
  number        = {4},
  pages         = {157-168},
  doi           = {10.1257/jep.15.4.157},
  __markedentry = {[kevin:2]},
  abstract      = {ARCH and GARCH models have become important tools in the analysis of time series data, particularly in financial applications. These models are especially useful when the goal of the study is to analyze and forecast volatility. This paper gives the motivation behind the simplest GARCH model and illustrates its usefulness in examining portfolio risk. Extensions are briefly discussed.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/Engle2001.PDF:PDF},
}

@Article{Markowitz1952,
  author        = {Markowitz, Harry},
  title         = {Portfolio Selection},
  journal       = {The Journal of Finance},
  year          = {1952},
  volume        = {7},
  number        = {1},
  pages         = {77-91},
  issn          = {1540-6261},
  doi           = {10.1111/j.1540-6261.1952.tb01525.x},
  url           = {http://dx.doi.org/10.1111/j.1540-6261.1952.tb01525.x},
  __markedentry = {[kevin:1]},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/Markowitz1952.pdf:PDF},
  publisher     = {Blackwell Publishing Ltd},
}

@Online{CNBC2018,
  author        = {Franck, Thomas},
  title         = {Obscure security linked to stock volatility plummets 80\% after hours, sparking worries of bigger market effect},
  year          = {2018},
  url           = {https://www.cnbc.com/2018/02/05/xiv-exchange-traded-security-linked-to-volatility-plummets-80-percent.html},
  organization  = {CNBC},
  urldate       = {2018-03-18},
  __markedentry = {[kevin:3]},
}

@InProceedings{Zhang04,
  author        = {Zhang, Harry},
  title         = {The Optimality of Naive Bayes},
  booktitle     = {Proceedings of the Seventeenth International Florida Artificial Intelligence Research Society Conference (FLAIRS 2004)},
  year          = {2004},
  editor        = {Barr, Valerie and Markov, Zdravko},
  location      = {South Beach, USA},
  __markedentry = {[kevin:4]},
  abstract      = {Naive Bayes is one of the most efficient and effective inductive learning algorithms for machine learning and data mining. Its competitive performance in classification is surprising, because the conditional independence assumption on which it is based, is rarely true in realworld applications. An open question is: what is the true reason for the surprisingly good performance of naive Bayes in classification? In this paper, we propose a novel explanation on the superb classification performance of naive Bayes. We show that, essentially, the dependence distribution; i.e., how the local dependence of a node distributes in each class, evenly or unevenly, and how the local dependencies of all nodes work together, consistently (supporting a certain classification) or inconsistently (canceling each other out), plays a crucial role. Therefore, no matter how strong the dependences among attributes are, naive Bayes can still be optimal if the dependences distribute evenly in classes, or if the dependences cancel each other out. We propose and prove a sufficient and necessary conditions for the optimality of naive Bayes. Further, we investigate the optimality of naive Bayes under the Gaussian distribution. We present and prove a sufficient condition for the optimality of naive Bayes, in which the dependence between attributes do exist. This provides evidence that dependence among attributes may cancel out each other. In addition, we explore when naive Bayes works well.},
  file          = {:C\:/Users/User/Dropbox/Master_Thesis/Text_mining_literature/Zhang2004.pdf:PDF},
}

@Article{YukselturkTucker2015,
  author        = {Yukselturk, Osman and Tucker, Jon},
  title         = {The impact of analyst sentiment on UK stock recommendations and target prices},
  journal       = {Accounting and Business Research},
  year          = {2015},
  volume        = {45},
  month         = nov,
  pages         = {869-904},
  __markedentry = {[kevin:1]},
  abstract      = {The aim of this paper is to investigate the relationship between narrative sentiment in analysts' company reports and their recommendation and target price outputs. We study an industry-balanced sample of 275 UK quoted company sell-side analyst reports over the period 2006-2010 using a content analysis methodology to measure net sentiment for a range of themes. We then model analysts' outputs against themed sentiment scores to analyse the impact of the Global Financial Crisis. We find that themed sentiments impact upon analysts' outputs, but their magnitude and direction vary over the pre-crisis, crisis and post-crisis periods. In particular, before the crisis we find a strong negative relationship between the macroeconomic and regulatory environment and report outputs, though this effect diminishes somewhat with the onset of the crisis, to be restored thereafter. Growth sentiment exerts a weak positive impact before the crisis which disappears thereafter. Financial performance sentiment becomes a significant positive driver of outputs following the crisis. There is evidently a "back to basics" approach following the crisis which restores financial fundamentals to the heart of stock analysis. Our findings provide some insight into the thought processes of analysts by identifying the dynamic relation between analysts' outputs and themed sentiments.},
  file          = {:C\:/Users/User/Dropbox/Master_Thesis/Text_mining_literature/YukselturkTucker2015.pdf:PDF},
}

@Article{Govindaraj2013,
  author        = {Govindaraj, Suresh and Livnat, Joshua and G. Savor, Pavel and Zhao, Chen},
  title         = {Large Price Changes and Subsequent Returns},
  year          = {2013},
  month         = jan,
  __markedentry = {[kevin:1]},
  abstract      = {We investigate whether large stock price changes are associated with short-term reversals or momentum, conditional on the issuance of analyst price target or earnings forecast revisions immediately following these price changes. Our study provides evidence that when analyst revisions occur immediately after large price shocks, stock prices exhibit momentum, suggesting the initial price change was based on new information. In contrast, when price changes are not followed by immediate analyst revisions, we document short-term reversals, indicating that the initial price shocks were probably caused by liquidity or noise traders. A trading strategy that is based on the direction of the price change and the existence of immediate analyst revisions in the same direction earns significant abnormal monthly calendar-time returns.},
  booktitle     = {SSRN Electronic Journal},
  file          = {:C\:/Users/User/Dropbox/Master_Thesis/Text_mining_literature/Govindaraj2013.pdf:PDF},
}

@Article{Domingos1997,
  author        = {Domingos, Pedro and Pazzani, Michael},
  title         = {On the Optimality of the Simple Bayesian Classifier under Zero-One Loss},
  journal       = {Machine Learning},
  year          = {1997},
  volume        = {29},
  number        = {2},
  month         = {Nov},
  pages         = {103--130},
  issn          = {1573-0565},
  doi           = {10.1023/A:1007413511361},
  url           = {https://doi.org/10.1023/A:1007413511361},
  __markedentry = {[kevin:3]},
  abstract      = {The simple Bayesian classifier is known to be optimal when attributes are independent given the class, but the question of whether other sufficient conditions for its optimality exist has so far not been explored. Empirical results showing that it performs surprisingly well in many domains containing clear attribute dependences suggest that the answer to this question may be positive. This article shows that, although the Bayesian classifier's probability estimates are only optimal under quadratic loss if the independence assumption holds, the classifier itself can be optimal under zero-one loss (misclassification rate) even when this assumption is violated by a wide margin. The region of quadratic-loss optimality of the Bayesian classifier is in fact a second-order infinitesimal fraction of the region of zero-one optimality. This implies that the Bayesian classifier has a much greater range of applicability than previously thought. For example, in this article it is shown to be optimal for learning conjunctions and disjunctions, even though they violate the independence assumption. Further, studies in artificial domains show that it will often outperform more powerful classifiers for common training set sizes and numbers of attributes, even if its bias is a priori much less appropriate to the domain. This article's results also imply that detecting attribute dependence is not necessarily the best way to extend the Bayesian classifier, and this is also verified empirically.},
  file          = {:C\:/Users/User/Dropbox/Master_Thesis/Text_mining_literature/DomingosPazzani1997.pdf:PDF},
}

@Article{Bollerslev1986,
  author        = {Bollerslev, Tim},
  title         = {Generalized autoregressive conditional heteroskedasticity},
  journal       = {Journal of Econometrics},
  year          = {1986},
  volume        = {31},
  number        = {3},
  pages         = {307 - 327},
  issn          = {0304-4076},
  doi           = {https://doi.org/10.1016/0304-4076(86)90063-1},
  url           = {http://www.sciencedirect.com/science/article/pii/0304407686900631},
  __markedentry = {[kevin:2]},
  abstract      = {A natural generalization of the ARCH (Autoregressive Conditional Heteroskedastic) process introduced in Engle (1982) to allow for past conditional variances in the current conditional variance equation is proposed. Stationarity conditions and autocorrelation structure for this new class of parametric models are derived. Maximum likelihood estimation and testing are also considered. Finally an empirical example relating to the uncertainty of the inflation rate is presented.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/Bollerslev1986.pdf:PDF},
}

@Article{EngleBollerslev1986,
  author        = {Engle, Robert F. and Bollerslev, Tim},
  title         = {Modelling the persistence of conditional variances},
  journal       = {Econometric Reviews},
  year          = {1986},
  volume        = {5},
  number        = {1},
  pages         = {1-50},
  doi           = {10.1080/07474938608800095},
  eprint        = {https://doi.org/10.1080/07474938608800095},
  url           = { 
        https://doi.org/10.1080/07474938608800095
    
},
  __markedentry = {[kevin:2]},
  abstract      = { This paper will discuss the current research in building models of conditional variances using the Autoregressive Conditional Heteroskedastic (ARCH) and Generalized ARCH (GARCH) formulations. The discussion will be motivated by a simple asset pricing theory which is particularly appropriate for examining futures contracts with risk averse agents. A new class of models defined to be integrated in variance is then introduced. This new class of models includes the variance analogue of a unit root in the mean as a special case. The models are argued to be both theoretically important for the asset pricing models and empirically relevant. The conditional density is then generalized from a normal to a Student-t with unknown degrees of freedom. By estimating the degrees of freedom, implications about the conditional kurtosis of these models and time aggregated models can be drawn. A further generalization allows the conditional variance to be a non-linear function of the squared innovations. Throughout empirical e imates of the logarithm of the exchange rate between the U.S. dollar and the Swiss franc are presented to illustrate the models. },
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/EngleBollerslev1986.pdf:PDF},
  publisher     = {Taylor \& Francis},
}

@Article{Engle1982,
  author        = {Engle, Robert F.},
  title         = {Autoregressive Conditional Heteroscedasticity with Estimates of the Variance of United Kingdom Inflation},
  journal       = {Econometrica},
  year          = {1982},
  volume        = {50},
  number        = {4},
  pages         = {987--1007},
  issn          = {00129682, 14680262},
  url           = {http://www.jstor.org/stable/1912773},
  __markedentry = {[kevin:2]},
  abstract      = {Traditional econometric models assume a constant one-period forecast variance. To generalize this implausible assumption, a new class of stochastic processes called autoregressive conditional heteroscedastic (ARCH) processes are introduced in this paper. These are mean zero, serially uncorrelated processes with nonconstant variances conditional on the past, but constant unconditional variances. For such processes, the recent past gives information about the one-period forecast variance. A regression model is then introduced with disturbances following an ARCH process. Maximum likelihood estimators are described and a simple scoring iteration formulated. Ordinary least squares maintains its optimality properties in this set-up, but maximum likelihood is more efficient. The relative efficiency is calculated and can be infinite. To test whether the disturbances follow an ARCH process, the Lagrange multiplier procedure is employed. The test is based simply on the autocorrelation of the squared OLS residuals. This model is used to estimate the means and variances of inflation in the U.K. The ARCH effect is found to be significant and the estimated variances increase substantially during the chaotic seventies.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/Engle1982.pdf:PDF},
  publisher     = {[Wiley, Econometric Society]},
}

@Article{ChenHaerdleJeong2010,
  author        = {Shiyi Chen and Wolfgang K. Härdle and Kiho Jeong},
  title         = {Forecasting volatility with support vector machine‐based GARCH model},
  journal       = {Journal of Forecasting},
  year          = {2010},
  volume        = {29},
  number        = {4},
  pages         = {406-433},
  doi           = {10.1002/for.1134},
  eprint        = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/for.1134},
  url           = {https://onlinelibrary.wiley.com/doi/abs/10.1002/for.1134},
  __markedentry = {[kevin:4]},
  abstract      = {Abstract Recently, support vector machine (SVM), a novel artificial neural network (ANN), has been successfully used for financial forecasting. This paper deals with the application of SVM in volatility forecasting under the GARCH framework, the performance of which is compared with simple moving average, standard GARCH, nonlinear EGARCH and traditional ANN‐GARCH models by using two evaluation measures and robust Diebold–Mariano tests. The real data used in this study are daily GBP exchange rates and NYSE composite index. Empirical results from both simulation and real data reveal that, under a recursive forecasting scheme, SVM‐GARCH models significantly outperform the competing models in most situations of one‐period‐ahead volatility forecasting, which confirms the theoretical advantage of SVM. The standard GARCH model also performs well in the case of normality and large sample size, while EGARCH model is good at forecasting volatility under the high skewed distribution. The sensitivity analysis to choose SVM parameters and cross‐validation to determine the stopping point of the recurrent SVM procedure are also examined in this study. Copyright © 2009 John Wiley \& Sons, Ltd.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/ChenHaerdleJeong2010.pdf:PDF},
  keywords      = {(recurrent) support vector machine, GARCH model, volatility forecasting, Diebold–Mariano test},
}

@Article{GavrishchakaBanerjee2006,
  author        = {Gavrishchaka, Valeriy and Banerjee, Supriya},
  title         = {Support Vector Machine as an Efficient Framework for Stock Market Volatility Forecasting},
  journal       = {Computational Management Science},
  year          = {2006},
  volume        = {3},
  number        = {2},
  month         = {02},
  pages         = {147-160},
  __markedentry = {[kevintikvic:4]},
  booktitle     = {Computational Management Science},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/GavrishchakaBanerjee2006.pdf:PDF},
}

@Article{GJR1993,
  author        = {Glosten, Lawrence R. and Jagannathan, Ravi and Runkle, David E.},
  title         = {On the Relation between the Expected Value and the Volatility of the Nominal Excess Return on Stocks},
  journaltitle  = {The Journal of Finance},
  year          = {1993},
  volume        = {48},
  number        = {5},
  pages         = {1779-1801},
  doi           = {10.1111/j.1540-6261.1993.tb05128.x},
  url           = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1540-6261.1993.tb05128.x},
  __markedentry = {[kevin:2]},
  abstract      = {We find support for a negative relation between conditional expected monthly return and conditional variance of monthly return, using a GARCH‐M model modified by allowing (1) seasonal patterns in volatility, (2) positive and negative innovations to returns having different impacts on conditional volatility, and (3) nominal interest rates to predict conditional variance. Using the modified GARCH‐M model, we also show that monthly conditional volatility may not be as persistent as was thought. Positive unanticipated returns appear to result in a downward revision of the conditional volatility whereas negative unanticipated returns result in an upward revision of conditional volatility.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/GJR1993.pdf:PDF},
}

@Article{RiskMetrics96,
  author        = {J.P.Morgan/Reuters},
  title         = {RiskMetrics (TM) - Technical Document},
  date          = {1996-12-17},
  urldate       = {2018-04-06},
  __markedentry = {[kevin:2]},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/Riskmetrics1996.pdf:PDF},
}

@Article{Nelson1991,
  author        = {Nelson, Daniel B.},
  title         = {Conditional Heteroskedasticity in Asset Returns: A New Approach},
  journaltitle  = {Econometrica},
  year          = {1991},
  volume        = {59},
  number        = {2},
  pages         = {347--370},
  issn          = {00129682, 14680262},
  __markedentry = {[kevin:2]},
  abstract      = {GARCH models have been applied in modelling the relation between conditional variance and asset risk premia. These models, however, have at least three major drawbacks in asset pricing applications: (i) Researchers beginning with Black (1976) have found a negative correlation between current returns and future returns volatility. GARCH models rule this out by assumption. (ii) GARCH models impose parameter restrictions that are often violated by estimated coefficients and that may unduly restrict the dynamics of the conditional variance process. (iii) Interpreting whether shocks to conditional variance "persist" or not is difficult in GARCH models, because the usual norms measuring persistence often do not agree. A new form of ARCH is proposed that meets these objections. The method is used to estimate a model of the risk premium on the CRSP Value-Weighted Market Index from 1962 to 1987.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/Nelson1991.pdf:PDF},
  publisher     = {[Wiley, Econometric Society]},
}

@Article{Zakoian1994,
  author        = {Zakoian, Jean-Michel},
  title         = {Threshold heteroskedastic models},
  journaltitle  = {Journal of Economic Dynamics and Control},
  year          = {1994},
  volume        = {18},
  number        = {5},
  pages         = {931 - 955},
  issn          = {0165-1889},
  doi           = {https://doi.org/10.1016/0165-1889(94)90039-6},
  __markedentry = {[kevin:2]},
  abstract      = {In this paper we consider a modification of the classical ARCH models introduced by Engle (1982). In this modified model the conditional standard deviation is a piecewise linear function of past values of the white noise. This specific form allows different reactions of the volatility to different signs of the lagged errors. Stationarity conditions are derived. Maximum likelihood and least squares estimation are also considered. Finally an empirical example relating to the French CAC stock index is presented and several specifications are compared.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/Zakoian1994.pdf:PDF},
  keywords      = {GARCH models, Asymmetries in volatility, Stationarity},
}

@Article{FrancisSoffer1997,
  author       = {Francis, Jennifer and Soffer, Leonard},
  title        = {The Relative Informativeness of Analysts' Stock Recommendations and Earnings Forecast Revisions},
  journaltitle = {Journal of Accounting Research},
  year         = {1997},
  volume       = {35},
  number       = {2},
  pages        = {193--211},
  issn         = {00218456, 1475679X},
  url          = {http://www.jstor.org/stable/2491360},
  file         = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/FrancisSoffer1997.pdf:PDF},
  journal      = {Journal of Accounting Research},
  publisher    = {[Accounting Research Center, Booth School of Business, University of Chicago, Wiley]},
}

@Article{Hirst1995,
  author        = {D. Eric Hirst and Lisa Koonce and Paul J. Simko},
  title         = {Investor Reactions to Financial Analysts' Research Reports},
  journaltitle  = {Journal of Accounting Research},
  year          = {1995},
  volume        = {33},
  number        = {2},
  pages         = {335--351},
  issn          = {00218456, 1475679X},
  __markedentry = {[kevin:1]},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/Hirst1995.pdf:PDF},
  publisher     = {[Accounting Research Center, Booth School of Business, University of Chicago, Wiley]},
}

@Article{AntweilerFrank2004,
  author        = {Antweiler, Werner and Frank, Murray Z. F.},
  title         = {Is All That Talk Just Noise? The Information Content of Internet Stock Message Boards},
  journal       = {The Journal of Finance},
  journaltitle  = {The Journal of Finance},
  date          = {2004},
  volume        = {59},
  number        = {3},
  pages         = {1259-1294},
  doi           = {10.1111/j.1540-6261.2004.00662.x},
  __markedentry = {[kevin:4]},
  abstract      = {Financial press reports claim that Internet stock message boards can move markets. We study the effect of more than 1.5 million messages posted on Yahoo! Finance and Raging Bull about the 45 companies in the Dow Jones Industrial Average and the Dow Jones Internet Index. Bullishness is measured using computational linguistics methods. Wall Street Journal news stories are used as controls. We find that stock messages help predict market volatility. Their effect on stock returns is statistically significant but economically small. Consistent with Harris and Raviv (1993), disagreement among the posted messages is associated with increased trading volume.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/Antweiler2004.pdf:PDF},
}

@Online{FleschWeb,
  author        = {Colmer, Ruth},
  title         = {The Flesch Reading Ease and Flesch-Kincaid Grade Level},
  url           = {https://readable.io/blog/the-flesch-reading-ease-and-flesch-kincaid-grade-level/},
  organization  = {Readable.io},
  urldate       = {2018-04-10},
  __markedentry = {[kevin:2]},
}

@Article{Jegadeesh2013,
  author       = {Jegadeesh, Narasimhan and Wu, Di},
  title        = {Word power: A new approach for content analysis},
  journaltitle = {Journal of Financial Economics},
  year         = {2013},
  volume       = {110},
  number       = {3},
  pages        = {712 - 729},
  note         = {Accepted Manuscript, available under \url{https://www.sciencedirect.com/science/article/pii/S0304405X13002328} (visited on 05/21/2018)},
  issn         = {0304-405X},
  doi          = {https://doi.org/10.1016/j.jfineco.2013.08.018},
  url          = {http://www.sciencedirect.com/science/article/pii/S0304405X13002328},
  urldate      = {2018-05-21},
  abstract     = {We present a new approach for content analysis to quantify document tone. We find a significant relation between our measure of the tone of 10-Ks and market reaction for both negative and positive words. We also find that the appropriate choice of term weighting in content analysis is at least as important as, and perhaps more important than, a complete and accurate compilation of the word list. Furthermore, we show that our approach circumvents the need to subjectively partition words into positive and negative word lists. Our approach reliably quantifies the tone of IPO prospectuses as well, and we find that the document score is negatively related to IPO underpricing.},
  file         = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/Jegadeesh2013.pdf:PDF},
  keywords     = {Content analysis, Lexicons, Term weighting},
}

@Article{Loughran2011,
  author        = {Loughran, Tim and McDonald, Bill},
  title         = {When Is a Liability Not a Liability? Textual Analysis, Dictionaries, and 10‐Ks},
  journaltitle  = {The Journal of Finance},
  year          = {2011},
  volume        = {66},
  number        = {1},
  pages         = {35-65},
  doi           = {10.1111/j.1540-6261.2010.01625.x},
  url           = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-6261.2010.01625.x},
  __markedentry = {[kevin:5]},
  abstract      = {Previous research uses negative word counts to measure the tone of a text. We show that word lists developed for other disciplines misclassify common words in financial text. In a large sample of 10‐Ks during 1994 to 2008, almost three‐fourths of the words identified as negative by the widely used Harvard Dictionary are words typically not considered negative in financial contexts. We develop an alternative negative word list, along with five other word lists, that better reflect tone in financial text. We link the word lists to 10‐K filing returns, trading volume, return volatility, fraud, material weakness, and unexpected earnings.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/Loughran2011.pdf:PDF},
}

@Article{Tetlock2007,
  author       = {Tetlock, Paul C.},
  title        = {Giving Content to Investor Sentiment: The Role of Media in the Stock Market},
  journaltitle = {The Journal of Finance},
  year         = {2007},
  volume       = {62},
  number       = {3},
  pages        = {1139-1168},
  doi          = {10.1111/j.1540-6261.2007.01232.x},
  url          = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-6261.2007.01232.x},
  abstract     = {I quantitatively measure the interactions between the media and the stock market using daily content from a popular Wall Street Journal column. I find that high media pessimism predicts downward pressure on market prices followed by a reversion to fundamentals, and unusually high or low pessimism predicts high market trading volume. These and similar results are consistent with theoretical models of noise and liquidity traders, and are inconsistent with theories of media content as a proxy for new information about fundamental asset values, as a proxy for market volatility, or as a sideshow with no relationship to asset markets.},
  file         = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/Tetlock2007.pdf:PDF},
}

@Article{Li2008,
  author        = {Li, Feng},
  title         = {Annual report readability, current earnings, and earnings persistence},
  journaltitle  = {Journal of Accounting and Economics},
  year          = {2008},
  volume        = {45},
  number        = {2},
  pages         = {221 - 247},
  issn          = {0165-4101},
  doi           = {https://doi.org/10.1016/j.jacceco.2008.02.003},
  url           = {http://www.sciencedirect.com/science/article/pii/S0165410108000141},
  __markedentry = {[kevin:1]},
  abstract      = {This paper examines the relation between annual report readability and firm performance and earnings persistence. I measure the readability of public company annual reports using the Fog index from the computational linguistics literature and the length of the document. I find that: (1) the annual reports of firms with lower earnings are harder to read (i.e., they have a higher Fog index and are longer); and (2) firms with annual reports that are easier to read have more persistent positive earnings.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/Li2008.pdf:PDF},
  keywords      = {Disclosure, Annual report readability, Profitability, Earnings persistence},
}

@Article{LehavyLiMerkley2011,
  author        = {Lehavy, Reuven and Li, Feng and Merkley, Kenneth},
  title         = {The Effect of Annual Report Readability on Analyst Following and the Properties of Their Earnings Forecasts},
  journaltitle  = {The Accounting Review},
  year          = {2011},
  volume        = {86},
  number        = {3},
  pages         = {1087-1115},
  doi           = {10.2308/accr.00000043},
  __markedentry = {[kevin:3]},
  abstract      = {This study examines the effect of the readability of firms’ written communication on the behavior of sell-side financial analysts. Using a measure of the readability of corporate 10-K filings, we document that analyst following, the amount of effort incurred to generate their reports, and the informativeness of their reports are greater for firms with less readable 10-Ks. Additionally, we find that less readable 10-Ks are associated with greater dispersion, lower accuracy, and greater overall uncertainty in analyst earnings forecasts. Overall, our results are consistent with the prediction of an increasing demand for analyst services for firms with less readable communication and a greater collective effort by analysts for firms with less readable disclosures. Our results contribute to the understanding of the role of analysts as information intermediaries for investors and the effect of the complexity of written financial communication on the usefulness of this information.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/LehavyLiMerkley2011.pdf:PDF},
}

@Article{LundholmRogoZhang2014,
  author       = {Lundholm, Russell J. and Rogo, Rafael and Zhang, Jenny Li},
  title        = {Restoring the Tower of Babel: How Foreign Firms Communicate with U.S. Investors},
  journaltitle = {The Accounting Review},
  year         = {2014},
  volume       = {89},
  number       = {4},
  month        = {07},
  pages        = {1453-1485},
  doi          = {10.2308/accr-50725},
  abstract     = {We examine the readability of text and the use of numbers in the annual filings and earnings press releases of foreign firms listed on U.S. stock exchanges. We find that foreign firms generally write clearer text and present relatively more numerical data than their U.S. firm counterparts. More importantly, we find that the readability of the text and use of numbers increases as the foreign firms get geographically further from the U.S. It also increases as the foreign firm's home country has greater differences in accounting standards or investor protection laws relative to the U.S. Further corroborating our results, we also find that these communication efforts are partially successful. Within a country, firms that produce relatively more readable disclosures attract relatively more U.S. institutional ownership. Collectively, our results suggest that foreign firms are responding to a perceived reluctance on the part of U.S. investors to own them and attempt to lower the investors' information disadvantage or psychological distance by providing clearer and more concrete disclosures.},
  booktitle    = {The Accounting Review},
  file         = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/LundholmRogoZhang2014.pdf:PDF},
}

@Article{VanGesten_etal_2001,
  author     = {Van Gestel, Tony and Suykens, Johan A.K. and Baestaens, Dirk-Emma and Lambrechts, Annemie and Lanckriet, Gert and Vandaele, Bruno and De Moor, Bart and Vandewalle, Joos},
  title      = {Financial Time Series Prediction Using Least Squares Support Vector Machines Within the Evidence Framework},
  year       = {2001},
  volume     = {12},
  number     = {4},
  month      = jul,
  pages      = {809--821},
  issn       = {1045-9227},
  doi        = {10.1109/72.935093},
  url        = {http://dx.doi.org/10.1109/72.935093},
  abstract   = {The Bayesian evidence framework is applied in this paper to least squares support vector machine (LS-SVM) regression in order to infer nonlinear models for predicting a financial time series and the related volatility. On the first level of inference, a statistical framework is related to the LS-SVM formulation which allows one to include the time-varying volatility of the market by an appropriate choice of several hyper-parameters. The hyper-parameters of the model are inferred on the second level of inference. The inferred hyper-parameters, related to the volatility, are used to construct a volatility model within the evidence framework. Model comparison is performed on the third level of inference in order to automatically tune the parameters of the kernel function and to select the relevant inputs. The LS-SVM formulation allows one to derive analytic expressions in the feature space and practical expressions are obtained in the dual space replacing the inner product by the related kernel function using Mercer's theorem. The one step ahead prediction performances obtained on the prediction of the weekly 90-day T-bill rate and the daily DAX30 closing prices show that significant out of sample sign predictions can be made with respect to the Pesaran-Timmerman test statistic},
  acmid      = {2326753},
  address    = {Piscataway, NJ, USA},
  file       = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/VanGesten_etal_2001.pdf:PDF},
  issue_date = {July 2001},
  journal    = {IEEE Transactions on Neural Networks},
  numpages   = {13},
  publisher  = {IEEE Press},
}

@Article{EngleNg1993,
  author        = {Engle, Robert F. and Ng, Victor K.},
  title         = {Measuring and Testing the Impact of News on Volatility},
  journaltitle  = {The Journal of Finance},
  year          = {1993},
  volume        = {48},
  number        = {5},
  pages         = {1749--1778},
  issn          = {00221082, 15406261},
  url           = {http://www.jstor.org/stable/2329066},
  __markedentry = {[kevin:2]},
  abstract      = {This paper defines the news impact curve which measures how new information is incorporated into volatility estimates. Various new and existing ARCH models including a partially nonparametric one are compared and estimated with daily Japanese stock return data. New diagnostic tests are presented which emphasize the asymmetry of the volatility response to news. Our results suggest that the model by Glosten, Jagannathan, and Runkle is the best parametric model. The EGARCH also can capture most of the asymmetry; however, there is evidence that the variability of the conditional variance implied by the EGARCH is too high.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/EngleNg1993.pdf:PDF},
  publisher     = {[American Finance Association, Wiley]},
}

@Article{KothariLiShort_2009,
  author        = {Kothari, S. P. and Li, Xu and Short, James E.},
  title         = {The Effect of Disclosures by Management, Analysts, and Business Press on Cost of Capital, Return Volatility, and Analyst Forecasts: A Study Using Content Analysis},
  journaltitle  = {The Accounting Review},
  year          = {2009},
  volume        = {84},
  number        = {5},
  pages         = {1639--1670},
  issn          = {00014826},
  url           = {http://www.jstor.org/stable/27784235},
  __markedentry = {[kevin:5]},
  abstract      = {We document systematic evidence of risk effects of disclosures culled from a virtually exhaustive set of sources from the print medium. We content analyze more than 100,000 disclosure reports by management, analysts, and news reporters (i.e., business press) in constructing firm-specific disclosure measures that are quantitative and amenable to replication. We expect credibility and timeliness differences in the disclosures by source, which would translate into differential cost of capital effects. We find that when content analysis indicates favorable disclosurs, the firm's risk, as proxied by the cost of capital, stock return volatility, and analyst forecast dispersion, declines significantly. In contrast, unfavorable disclosures are accompanied by significant increases in risk measures. Analysis of disclosures by source—corporations, analysts, and the business press—reveals that negative disclosures from business press sources result in increased cost of capital and return volatility, and favorable reports from business press reduce the cost of capital and return volatility.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/KothariLiShort_2009.pdf:PDF},
  publisher     = {American Accounting Association},
}

@Article{GavrishchakaGanguli2001,
  author       = {Gavrishchaka, Valeriy V. and Ganguli, Supriya B.},
  title        = {Support vector machine as an efficient tool for high‐dimensional data processing: Application to substorm forecasting},
  journaltitle = {Journal of Geophysical Research: Space Physics},
  year         = {2001},
  volume       = {106},
  number       = {A12},
  pages        = {29911-29914},
  doi          = {10.1029/2001JA900118},
  eprint       = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2001JA900118},
  url          = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2001JA900118},
  abstract     = {The support vector machine (SVM) has been used to model solar wind‐driven geomagnetic substorm activity characterized by the auroral electrojet (AE) index. The focus of the present study, which is the first application of the SVM to space physics problems, is reliable prediction of large‐amplitude substorm events from solar wind and interplanetary magnetic field data. This forecasting problem is important for many practical applications as well as for further understanding of the overall substorm dynamics. SVM has been trained on symbolically encoded AE index time series to perform supercritical/subcritical classification with respect to an application‐dependent threshold. It is shown that SVM performance can be comparable to or even superior to that of the neural networks model. The advantages of the SVM‐based techniques are expected to be much more pronounced in future space weather forecasting models, which will incorporate many types of high‐dimensional, multiscale input data once real time availability of this information becomes technologically feasible.},
  file         = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/GavrishchakaGanguli2001.pdf:PDF},
}

@Article{DeFrancoVasvariWittenberg_2009,
  author        = {De Franco, Gus and Vasvari, Florin P. and Wittenberg-Moerman, Regina},
  title         = {The Informational Role of Bond Analysts},
  journaltitle  = {Journal of Accounting Research},
  year          = {2009},
  volume        = {47},
  number        = {5},
  pages         = {1201--1248},
  issn          = {00218456, 1475679X},
  url           = {http://www.jstor.org/stable/40389224},
  __markedentry = {[kevin:1]},
  abstract      = {This study uses a large sample of sell-side bond analysts' reports to examine the properties of recommendations provided by bond analysts and the impact of these recommendations on bond securities. First, we document that the distribution of bond analysts' buy, hold, and sell recommendations is skewed positively, but less so than the distribution of equity analysts' recommendations. The positive skewness in bond analysts' recommendations is greater for low than for high credit quality bonds. Second, we find that bond analysts' reports generate bond trading and return reactions that are both economically significant and greater for low credit quality bonds. The bond market reaction is greater for bond analysts' reports than for equity analysts' reports. Finally, while both bond and equity analysts lead rating agency announcements, we find no evidence of a difference in timeliness between bond and equity analysts' reports. Overall, our results are consistent with bond analysts issuing more negative reports than equity analysts and providing more information about low credit quality bonds as a result of the asymmetric demand for negative information by bond investors.},
  file          = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/DeFrancoVasvariWittenberg_2009.pdf:PDF},
  publisher     = {[Accounting Research Center, Booth School of Business, University of Chicago, Wiley]},
}

@Article{DonaldsonKamstra1997,
  author       = {Donaldson, Glen R. and Kamstra, Mark},
  title        = {An artificial neural network-GARCH model for international stock return volatility},
  journaltitle = {Journal of Empirical Finance},
  year         = {1997},
  volume       = {4},
  number       = {1},
  pages        = {17 - 46},
  issn         = {0927-5398},
  doi          = {https://doi.org/10.1016/S0927-5398(96)00011-4},
  url          = {http://www.sciencedirect.com/science/article/pii/S0927539896000114},
  abstract     = {We construct a seminonparametric nonlinear GARCH model, based on the Artificial Neural Network (ANN) literature, and evaluate its ability to forecast stock return volatility in London, New York, Tokyo and Toronto. In-sample and out-of-sample comparisons reveal that our ANN model captures volatility effects overlooked by GARCH, EGARCH and GJR models and produces out-of-sample volatility forecasts which encompass those from other models. We also document important differences between volatility in international markets, such as the substantial persistence of volatility effects in Japan relative to North American and European markets.},
  file         = {:/Users/kevintikvic/Dropbox/Master_Thesis/Text_mining_literature/DonaldsonKamstra1997.pdf:PDF},
  keywords     = {Volatility, Stock prices, ARCH, Artificial neural networks},
}

@Online{Varian-NYT-2004,
  author        = {Varian, Hal R.},
  title         = {Good Stock Advice or Online Noise?},
  year          = {2014},
  date          = {2004-09-23},
  url           = {https://www.nytimes.com/2004/09/23/business/good-stock-advice-or-online-noise.html},
  organization  = {The New York Times},
  urldate       = {2018-04-20},
  __markedentry = {[kevin:3]},
}

@MastersThesis{Pulliza2015,
  author      = {Pulliza, Jonathan L.},
  title       = {An Analysis of Speculative Language in SEC 10-K Filings},
  institution = {University of North Carolina at Chapel Hill},
  year        = {2015},
  type        = {mathesis},
  url         = {https://cdr.lib.unc.edu/indexablecontent/uuid:c01f358b-cfb0-46ce-9b5b-cf4f10b18438},
  urldate     = {2018-05-27},
  abstract    = {This study applies sentiment analysis techniques to model the usage of speculation within a collection of financial documents. The model is trained on the MPQA corpus to extract features that correlate with speculative sentences and applied to a collection of SEC 10-K documents from a five year period. The documents with the highest amount of speculation contained a different concentration of terms compared to the entire collection, and the sentences mostly consisted of explaining potential risks concerning projects, taxes, and pensions.},
  file        = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/Pulliza_MastersThesis.pdf:PDF},
}

@Article{MyskovaHajekOlej2018,
  author        = {Myšková, Renáta and Hájek, Petr and Olej, Vladimir},
  title         = {Predicting Abnormal Stock Return Volatility Using Textual Analysis of News ? A Meta-Learning Approach},
  journal       = {Amfiteatru Economic},
  year          = {2018},
  volume        = {20},
  number        = {47},
  pages         = {185--201},
  __markedentry = {[kevin:3]},
  abstract      = {Textual analysis of news articles is increasingly important in predicting stock prices. Previous research has intensively utilized the textual analysis of news and other firm-related documents in volatility prediction models. It has been demonstrated that the news may be related to abnormal stock price behavior subsequent to their dissemination. However, previous studies to date have tended to focus on linear regression methods in predicting volatility. Here, we show that non-linear models can be effectively employed to explain the residual variance of the stock price. Moreover, we use meta-learning approach to simulate the decision-making process of various investors. The results suggest that this approach significantly improves the prediction accuracy of abnormal stock return volatility. The fact that the length of news articles is more important than news sentiment in predicting stock return volatility is another important finding. Notably, we show that Rotation forest performs particularly well in terms of both the accuracy of abnormal stock return volatility and the performance on imbalanced volatility data.
},
  file          = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/MyskovaHajekOlej_2018.pdf:PDF},
}

@InProceedings{LiuLiuWangTsai_2016,
  author        = {Liu, Yu-Wen and Liu, Liang-Chih and Wang, Chuan-Ju and Tsai, Ming-Feng},
  title         = {FIN10K: A Web-based Information System for Financial Report Analysis and Visualization},
  booktitle     = {Proceedings of the 25th ACM International on Conference on Information and Knowledge Management},
  year          = {2016},
  series        = {CIKM '16},
  publisher     = {ACM},
  isbn          = {978-1-4503-4073-1},
  pages         = {2441--2444},
  doi           = {10.1145/2983323.2983328},
  url           = {http://doi.acm.org/10.1145/2983323.2983328},
  __markedentry = {[kevin:3]},
  abstract      = {In this demonstration, we present FIN10K, a web-based information system that facilitates the analysis of textual information in financial reports. The proposed system has three main components: (1) a 10-K Corpus, including an inverted index of financial reports on Form 10-K, several numerical finance measures, and pre-trained word embeddings; (2) an information retrieval system; and (3) two data visualizations of the analyzed results. The system can be of great help in revealing valuable insights within large amounts of textual information. The system is now online available at http: //clip.csie.org/10K/.},
  file          = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/LiuLiuWangTsai_2016.pdf:PDF},
}

@InProceedings{NoppHanbury2015,
  author    = {Nopp, Clemens and Hanbury, Allan},
  title     = {Detecting Risks in the Banking System by Sentiment Analysis},
  booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year      = {2015},
  editor    = {Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  location  = {Lisbon, Portugal},
  pages     = {591-600},
  abstract  = {In November 2014, the European Cen- tral Bank (ECB) started to directly su- pervise the largest banks in the Euro- zone via the Single Supervisory Mechanism (SSM). While supervisory risk assessments are usually based on quantitative data and surveys, this work explores whether sentiment analysis is capable of measuring a bank’s attitude and opinions towards risk by analyzing text data. For realizing this study, a collection consisting of more than 500 CEO letters and outlook sections extracted from bank annual reports is built up. Based on these data, two distinct experiments are conducted. The evaluations find promising opportunities, but also limitations for risk sentiment analysis in banking supervision. At the level of individual banks, predictions are relatively inaccurate. In contrast, the analysis of aggregated figures revealed strong and significant correlations between uncertainty or negativity in textual disclosures and the quantitative risk indicator’s future evolution. Risk sentiment analysis should therefore rather be used for macroprudential analyses than for assessments of individual banks.},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/NoppHanbury2015.pdf:PDF},
}

@Article{TsaiWang2016,
  author        = {Tsai, Ming-Feng and Wang, Chuan-Ju},
  title         = {On the Risk Prediction and Analysis of Soft Information in Finance Reports},
  journaltitle  = {European Journal of Operational Research},
  year          = {2016},
  volume        = {257},
  number        = {1},
  pages         = {243-250},
  __markedentry = {[kevin:5]},
  abstract      = {We attempt in this paper to utilize soft information in financial reports to analyze financial risk among companies. Specifically, on the basis of the text information in financial reports, which is the so-called soft information, we apply analytical techniques to study relations between texts and financial risk. Fur- thermore, we conduct a study on financial sentiment analysis by using a finance-specific sentiment lex- icon to examine the relations between financial sentiment words and financial risk. A large collection of financial reports published annually by publicly-traded companies is employed to conduct our exper- iments; moreover, two analytical techniques – regression and ranking methods – are applied to conduct these analyses. The experimental results show that, based on a bag-of-words model, using only finan- cial sentiment words results in performance comparable to using the whole texts; this confirms the im- portance of financial sentiment words with respect to risk prediction. In addition to this performance comparison, via the learned models, we draw attention to some strong and interesting correlations be- tween texts and financial risk. These valuable findings yield greater insight and understanding into the usefulness of soft information in financial reports and can be applied to a broad range of financial and accounting applications.},
  file          = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/TsaiWang2016.pdf:PDF},
}

@Article{TsaiWangChien2016,
  author        = {Tsai, Ming-Feng and Wang, Chuan-Ju and Chien, Po-Chuan},
  title         = {Discovering Finance Keywords via Continuous-Space Language Models},
  journal       = {ACM Transactions on Management Information Systems},
  year          = {2016},
  volume        = {7},
  number        = {3},
  doi           = {10.1145/2948072},
  url           = {http://dx.doi.org/10.1145/2948072},
  __markedentry = {[kevin:4]},
  abstract      = {The growing amount of public financial data makes it increasingly important to learn how to discover valuable information for financial decision making. This article proposes an approach to discovering financial keywords from a large number of financial reports. In particular, we apply the continuous bag-of-words (CBOW) model, a well-known continuous-space language model, to the textual information in 10-K financial reports to discover new finance keywords. In order to capture word meanings to better locate financial terms, we also present a novel technique to incorporate syntactic information into the CBOW model. Experimental results on four prediction tasks using the discovered keywords demonstrate that our approach is effective for discovering predictability keywords for post-event volatility, stock volatility, abnormal trading volume, and excess return predictions. We also analyze the discovered keywords that attest to the ability of the proposed method to capture both syntactic and contextual information between words. This shows the success of this method when applied to the field of finance.},
  file          = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/TsaiWangChien2016.pdf:PDF},
}

@InProceedings{WangTsaiLiuChang2013,
  author        = {Wang, Chuan-Ju and Tsai, Ming-Fengand Liu, Tse and Chang, Chin-Ting},
  title         = {Financial Sentiment Analysis for Risk Prediction},
  booktitle     = {International Joint Conference on Natural Language Processing (IJCNLP)},
  year          = {2013},
  location      = {Nagoya, Japan},
  pages         = {802--808},
  url           = {http://www.aclweb.org/anthology/I13-1097},
  urldate       = {2018-04-24},
  __markedentry = {[kevin:5]},
  abstract      = {This paper attempts to identify the importance of sentiment words in financial reports on financial risk. By using a financespecific sentiment lexicon, we apply regression and ranking techniques to analyze the relations between sentiment words and financial risk. The experimental results show that, based on the bag-of-words model, models trained on sentiment words only result in comparable performance to those on origin texts, which confirms the importance of financial sentiment words on risk prediction. Furthermore, the learned models suggest strong correlations between financial sentiment words and risk of companies. As a result, these findings are of great value for providing us more insight and understanding into the impact of financial sentiment words in financial reports.},
  file          = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/WangTsaiLiuChang2013.pdf:PDF},
}

@Online{McKinsey_2013,
  author        = {Kremer, Andreas and Strobel, Florian and Malzkorn, Wolfgang},
  title         = {Ratings revisited: Textual analysis for better risk management},
  year          = {2013},
  url           = {https://www.mckinsey.com/business-functions/risk/our-insights/ratings-revisited-textual-analysis-for-better-risk-management},
  organization  = {McKinsey \& Company},
  urldate       = {2018-04-24},
  __markedentry = {[kevin:4]},
}

@Online{RMM_2015,
  author        = {Heires, Katherine},
  title         = {Sentiment Analysis: Are You Feeling Risky?},
  year          = {2015},
  date          = {2015-12-01},
  url           = {http://www.rmmagazine.com/2015/12/01/sentiment-analysis-are-you-feeling-risky/},
  organization  = {Risk Management Magazine},
  urldate       = {2018-04-24},
  __markedentry = {[kevin:4]},
}

@Unpublished{Gandhi_LM_2018,
  author        = {Gandhi, Priyank and Loughran, Tim and McDonald, Bill},
  title         = {Using Annual Report Sentiment as a Proxy for Financial Distress in U.S. Banks (March 28, 2018). Available at SSRN: https://ssrn.com/abstract=2905225 or http://dx.doi.org/10.2139/ssrn.2905225},
  year          = {2018},
  date          = {2018-03-28},
  pubstate      = {Working Paper},
  url           = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2905225},
  urldate       = {2018-04-24},
  __markedentry = {[kevin:4]},
  abstract      = {Current measures of bank distress find marginal value in predictive variables beyond a capital adequacy ratio and tend to miss extreme events impacting the entire sector. Our paper advocates a new proxy for bank distress: sentiment measures from banks’ annual reports. After controlling for popular forecasting variables used in the literature, we find that more negative sentiment in the annual report is associated with larger delisting probabilities, lower odds of paying subsequent dividends, higher subsequent loan loss provisions, and lower future ROA. Our findings suggest that regulators could augment current early warning systems for banks and the banking sector—where the measures are based exclusively on financial statement data—by using the frequency of negative words in banks’ annual reports.},
  file          = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/Gandhi_LM_2018.pdf:PDF},
}

@InProceedings{TsaiWang2014,
  author        = {Tsai, Ming-Feng and Wang, Chuan-Ju},
  title         = {Financial Keyword Expansion via Continuous Word Vector Representations},
  booktitle     = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year          = {2014},
  location      = {Doha, Qatar},
  doi           = {10.3115/v1/D14-1152},
  url           = {http://www.aclweb.org/anthology/D14-1152},
  urldate       = {2018-04-24},
  __markedentry = {[kevin:4]},
  abstract      = {This paper proposes to apply the continuous vector representations of words for discovering keywords from a ﬁnancial sen-timent lexicon. In order to capture more keywords, we also incorporate syntactic information into the Continuous Bag-of-Words (CBOW) model. Experimental results on a task of ﬁnancial risk prediction using the discovered keywords demonstrate that the proposed approach is good at predicting ﬁnancial risk.},
  file          = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/TsaiWang2014.pdf:PDF},
}

@InProceedings{TsaiWang2013,
  author        = {Tsai, Ming-Feng and Wang, Chuan-Ju},
  title         = {Risk Ranking from Financial Reports},
  booktitle     = {Proceedings of the 35th European Conference on Advances in Information Retrieval (ECIR) - LNCS7814},
  year          = {2013},
  editor        = {Serdyukov, Pavel and Braslavski, Pavel and Kuznetsov, Sergei O. and Kamps, Jaap and Rüger, Stefan and Agichtein, Eugene and Segalovich, Ilya and Yilmaz, Emine},
  publisher     = {Springer},
  location      = {Moscow, Russia},
  isbn          = {978-3-642-36972-8},
  pages         = {804--807},
  doi           = {10.1007/978-3-642-36973-5_89},
  url           = {http://dx.doi.org/10.1007/978-3-642-36973-5_89},
  urldate       = {2018-04-24},
  __markedentry = {[kevin:5]},
  abstract      = {This paper attempts to use soft information in finance to rank the risk levels of a set of companies. Specifically, we deal with a ranking problem with a collection of financial reports, in which each report is associated with a company. By using text information in the reports, which is so-called the soft information, we apply learning-to-rank techniques to rank a set of companies to keep them in line with their relative risk levels. In our experiments, a collection of financial reports, which are annually published by publicly-traded companies, is employed to evaluate our ranking approach; moreover, a regression-based approach is also carried out for comparison. The experimental results show that our ranking approach not only significantly outperforms the regression-based one, but identifies some interesting relations between financial terms.},
  address       = {Berlin, Heidelberg},
  file          = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/TsaiWang2013.pdf:PDF;:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/ECIR_2013_proceedings.pdf:PDF;:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/TsaiWang2013_onepager.pdf:PDF},
}

@InProceedings{TsaiWang2012,
  author        = {Tsai, Ming-Feng and Wang, Chuan-Ju},
  title         = {Visualization on Financial Terms via Risk Ranking from Financial Reports},
  booktitle     = {Proceedings of the 24th International Conference on Computational Linguistics (COLING 2012)},
  year          = {2012},
  publisher     = {International Conference on Computational Linguistics (COLING)},
  location      = {Mumbai, India},
  pages         = {447--452},
  url           = {http://www.aclweb.org/anthology/C12-3056},
  urldate       = {2018-04-24},
  __markedentry = {[kevin:3]},
  file          = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/TsaiWang2012.pdf:PDF},
}

@Article{HajekOlejMyskova_2013,
  author        = {Hájek, Petr and Olej, Vladimir and Myšková, Renáta},
  title         = {Forecasting stock prices using sentiment information in annual reports - A neural network and support vector regression approach},
  journal       = {WSEAS Transactions on Business and Economics},
  year          = {2013},
  volume        = {10},
  issue         = {4},
  pages         = {293-305},
  url           = {http://www.wseas.org/multimedia/journals/economics/2013/235702-202.pdf},
  urldate       = {2018-04-24},
  __markedentry = {[kevin:4]},
  abstract      = {Stock price forecasting has been mostly realized using quantitative information. However, recent studies have demonstrated that sentiment information hidden in corporate annual reports can be successfully used to predict short-run stock price returns. Soft computing methods, like neural networks and support vector regression, have shown promising results in the forecasting of stock price due to their ability to model complex non-linear systems. In this paper, we apply several neural networks and ε-support vector regression models to predict the yearly change in the stock price of U.S. firms. We demonstrate that neural networks and ε-support vector regression perform better than linear regression models especially when using the sentiment information. The change in the sentiment of annual reports seems to be an important determinant of long-run stock price change. Concretely, the negative and uncertainty categories of terms were the key factors of the stock price return. Profitability and technical analysis ratios have significant effect on the long-run return, too.},
  file          = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/HajekOlejMyskova_2013.pdf:PDF},
}

@Article{EnglePatton_2001,
  author        = {Engle, Robert F. and Patton, Andrew J.},
  title         = {What good is a volatility model?},
  journal       = {Quantitative Finance},
  year          = {2001},
  volume        = {1},
  pages         = {237--245},
  url           = {http://www.stern.nyu.edu/rengle/EnglePattonQF.pdf},
  urldate       = {2018-04-24},
  __markedentry = {[kevin:2]},
  abstract      = {A volatility model must be able to forecast volatility; this is the central requirement in almost all financial applications. In this paper we outline some stylized facts about volatility that should be incorporated in a model: pronounced persistence and mean-reversion, asymmetry such that the sign of an innovation also affects volatility and the possibility of exogenous or pre-determined variables influencing volatility. We use data on the Dow Jones Industrial Index to illustrate these stylized facts, and the ability of GARCH-type models to capture these features. We conclude with some challenges for future research in this area.},
  file          = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/EnglePatton_2001.pdf:PDF},
}

@Article{HansenLunde,
  author        = {Hansen, Peter R. and Lunde, Asger},
  title         = {A forecast comparison of volatility models: does anything beat a GARCH(1,1)?},
  journal       = {Journal of Applied Econometrics},
  year          = {2005},
  volume        = {20},
  number        = {7},
  pages         = {873-889},
  doi           = {10.1002/jae.800},
  url           = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jae.800},
  urldate       = {2018-04-24},
  __markedentry = {[kevin:2]},
  abstract      = {Abstract We compare 330 ARCH‐type models in terms of their ability to describe the conditional variance. The models are compared out‐of‐sample using DM–\$ exchange rate data and IBM return data, where the latter is based on a new data set of realized variance. We find no evidence that a GARCH(1,1) is outperformed by more sophisticated models in our analysis of exchange rates, whereas the GARCH(1,1) is clearly inferior to models that can accommodate a leverage effect in our analysis of IBM returns. The models are compared with the test for superior predictive ability (SPA) and the reality check for data snooping (RC). Our empirical results show that the RC lacks power to an extent that makes it unable to distinguish ‘good’ and ‘bad’ models in our analysis.},
  file          = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/HansenLunde_2005.pdf:PDF},
}

@Article{MittnikRobinzonovSpindler_2015,
  author    = {Mittnik, Stefan and Robinzonov, Nikolay and Spindler, Martin},
  title     = {Stock market volatility: Identifying major drivers and the nature of their impact},
  journal   = {Journal of Banking \& Finance},
  year      = {2015},
  volume    = {58},
  pages     = {1 - 14},
  issn      = {0378-4266},
  doi       = {https://doi.org/10.1016/j.jbankfin.2015.04.003},
  abstract  = {Financial-market risk, commonly measured in terms of asset-return volatility, plays a fundamental role in investment decisions, risk management and regulation. In this paper, we investigate a new modeling strategy that helps to better understand the forces that drive market risk. We use componentwise gradient boosting techniques to identify financial and macroeconomic factors influencing volatility and to assess the specific nature of their influence. Componentwise boosting is capable of producing parsimonious models from a, possibly, large number of predictors and—in contrast to other related techniques—allows a straightforward interpretation of the parameter estimates. Considering a wide range of potential risk drivers, we apply boosting to derive monthly volatility predictions for the equity market represented by S&P 500 index. Comparisons with commonly-used GARCH and EGARCH benchmark models show that our approach substantially improves out-of-sample volatility forecasts for short- and longer-run horizons. The results indicate that risk drivers affect future volatility in a nonlinear fashion.},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/MittnikRobinzonovSpindler_2015.pdf:PDF},
  keywords  = {Componentwise boosting, Financial market risk, Forecasting, GARCH, Exponential GARCH, Variable selection},
  timestamp = {2018-05-02},
}

@Article{KumarRavi2016,
  author    = {Kumar, Shravan and Ravi, Vadlamani},
  title     = {A survey of the applications of text mining in financial domain},
  journal   = {Knowledge-Based Systems},
  year      = {2016},
  volume    = {114},
  pages     = {128 - 147},
  issn      = {0950-7051},
  doi       = {https://doi.org/10.1016/j.knosys.2016.10.003},
  abstract  = {Text mining has found a variety of applications in diverse domains. Of late, prolific work is reported in using text mining techniques to solve problems in financial domain. The objective of this paper is to provide a state-of-the-art survey of various applications of Text mining to finance. These applications are categorized broadly into FOREX rate prediction, stock market prediction, customer relationship management (CRM) and cyber security. Since finance is a service industry, these problems are paramount in operational and customer growth aspects. We reviewed 89 research papers that appeared during the period 2000–2016, highlighted some of the issues, gaps, key challenges in this area and proposed some future research directions. Finally, this review can be extremely useful to budding researchers in this area, as many open problems are highlighted.},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/KumarRavi2016.pdf:PDF},
  keywords  = {Text mining, Financial applications, FOREX rate prediction, Stock market prediction, Customer relationship management, Cyber security},
  timestamp = {2018-05-02},
}

@Unpublished{Jurafsky_Draft_2017,
  author    = {Jurafsky, Dan and Martin, James H.},
  title     = {Speech and Language Processing},
  year      = {2017},
  subtitle  = {An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition},
  note      = {Draft of the 3rd edition - preprint as of 08/28/2017, available under \url{https://web.stanford.edu/~jurafsky/slp3/} (visited on 05/11/2018)},
  url       = {https://web.stanford.edu/~jurafsky/slp3/},
  urldate   = {2018-05-11},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/Jurafsky_BOOK.pdf:PDF},
  timestamp = {2018-05-11},
}

@Book{Gries_2009,
  author    = {Gries, Stefan T.},
  title     = {Quantitative Corpus Linguistics with R: A Practical Introduction},
  year      = {2009},
  publisher = {Routledge (Taylor \& Francis Group)},
  timestamp = {2018-05-11},
}

@Article{LM-meta-2016,
  author        = {Loughran, Tim and McDonald, Bill},
  title         = {Textual Analysis in Accounting and Finance: A Survey},
  journal       = {Journal of Accounting Research},
  year          = {2016},
  volume        = {54},
  number        = {4},
  pages         = {1187-1230},
  doi           = {10.1111/1475-679X.12123},
  url           = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1475-679X.12123},
  urldate       = {2018-05-23},
  __markedentry = {[kevin:5]},
  abstract      = {Relative to quantitative methods traditionally used in accounting and finance, textual analysis is substantially less precise. Thus, understanding the art is of equal importance to understanding the science. In this survey, we describe the nuances of the method and, as users of textual analysis, some of the tripwires in implementation. We also review the contemporary textual analysis literature and highlight areas of future research.},
  file          = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/Loughran2016.pdf:PDF},
  keywords      = {D82, D83, G14, G18, G30, M40, M41, textual analysis, sentiment analysis, bag of words, readability, word lists, Zipf's law, cosine similarity, Naïve Bayes},
  timestamp     = {2018-05-18},
}

@Book{ManningSchutze_IR_2008,
  author        = {Manning, Christopher D. and Raghavan, Prabhakar and Sch\"{u}tze, Hinrich},
  title         = {Introduction to Information Retrieval},
  year          = {2008},
  publisher     = {Cambridge University Press},
  isbn          = {0521865719, 9780521865715},
  url           = {https://nlp.stanford.edu/IR-book/},
  urldate       = {2018-05-19},
  __markedentry = {[kevin:3]},
  file          = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/Manning_Raghavan_Schuetze_IR_2009.pdf:PDF},
  timestamp     = {2018-05-19},
}

@Article{Nizer_BovespaVola_2012,
  author    = {Nizer, Philippe S.M. and Nievola, Julio Cesar},
  title     = {Predicting published news effect in the Brazilian stock market},
  journal   = {Expert Systems with Applications},
  year      = {2012},
  volume    = {39},
  number    = {12},
  pages     = {10674 - 10680},
  issn      = {0957-4174},
  doi       = {https://doi.org/10.1016/j.eswa.2012.02.162},
  abstract  = {The Efficient Market Hypothesis states that the value of an asset is given by all information available in the present moment. However, there is no possibility that a single financial analyst be aware of all published news which refers to a collection of stocks in the moment they are published. Thus, a computer system that applies text mining techniques and the GARCH model for predicting the volatility of financial assets may helps analysts and simple investors classifying automatically the news which cause the higher impact on stock market behavior. This work has the goal of creating a method for analyzing Portuguese written news’s content about companies that have their stocks negotiated in a stock market and trying to predict what kind of effect these news will cause in the Brazilian stock market behavior. Also, it was demonstrated in this study that it is possible to find out whether certain news may cause a considerable impact on prices of a negotiated stock.},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/NizerNievola2012.pdf:PDF},
  keywords  = {Text mining, Volatility forecast, Stock market, News effect},
  timestamp = {2018-05-19},
}

@Article{Nassirtousi_Meta_2014,
  author    = {Nassirtoussi, Arman Khadjeh and Aghabozorgi, Saeed and Wah, Teh Ying and Ngo, David Chek Ling},
  title     = {Text mining for market prediction: A systematic review},
  journal   = {Expert Systems with Applications},
  year      = {2014},
  volume    = {41},
  number    = {16},
  pages     = {7653 - 7670},
  issn      = {0957-4174},
  doi       = {https://doi.org/10.1016/j.eswa.2014.06.009},
  abstract  = {The quality of the interpretation of the sentiment in the online buzz in the social media and the online news can determine the predictability of financial markets and cause huge gains or losses. That is why a number of researchers have turned their full attention to the different aspects of this problem lately. However, there is no well-rounded theoretical and technical framework for approaching the problem to the best of our knowledge. We believe the existing lack of such clarity on the topic is due to its interdisciplinary nature that involves at its core both behavioral-economic topics as well as artificial intelligence. We dive deeper into the interdisciplinary nature and contribute to the formation of a clear frame of discussion. We review the related works that are about market prediction based on online-text-mining and produce a picture of the generic components that they all have. We, furthermore, compare each system with the rest and identify their main differentiating factors. Our comparative analysis of the systems expands onto the theoretical and technical foundations behind each. This work should help the research community to structure this emerging field and identify the exact aspects which require further research and are of special significance.},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/Nassirtoussi_etal_2014.pdf:PDF},
  keywords  = {Online sentiment analysis, Social media text mining, News sentiment analysis, FOREX market prediction, Stock prediction based on news},
  timestamp = {2018-05-19},
}

@Article{ZobelMoffat_termweights_1998,
  author     = {Zobel, Justin and Moffat, Alistair},
  title      = {Exploring the Similarity Space},
  journal    = {ACM SIGIR Forum},
  year       = {1998},
  volume     = {32},
  number     = {1},
  pages      = {18--34},
  issn       = {0163-5840},
  doi        = {10.1145/281250.281256},
  url        = {http://doi.acm.org/10.1145/281250.281256},
  abstract   = {Ranked queries are used to locate relevant documents in text databases. In a ranked query a list of terms is specified, then the documents that most closely match the query are returned---in decreasing order of similarity---as answers. Crucial to the efficacy of ranked querying is the use of a similarity heuristic, a mechanism that assigns a numeric score indicating how closely a document and the query match. In this note we explore and categorise a range of similarity heuristics described in the literature. We have implemented all of these measures in a structured way, and have carried out retrieval experiments with a substantial subset of these measures.Our purpose with this work is threefold: first, in enumerating the various measures in an orthogonal framework we make it straightforward for other researchers to describe and discuss similarity measures; second, by experimenting with a wide range of the measures, we hope to observe which features yield good retrieval behaviour in a variety of retrieval environments; and third, by describing our results so far, to gather feedback on the issues we have uncovered. We demonstrate that it is surprisingly difficult to identify which techniques work best, and comment on the experimental methodology required to support any claims as to the superiority of one method over another.},
  file       = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/ZobelMoffat_termweights_1998.pdf:PDF},
  issue_date = {Spring 1998},
  publisher  = {ACM},
  timestamp  = {2018-05-19},
}

@Article{Paye_VolaMacro_2012,
  author    = {Paye, Bradley S.},
  title     = {‘Déjà vol’: Predictive regressions for aggregate stock market volatility using macroeconomic variables},
  journal   = {Journal of Financial Economics},
  year      = {2012},
  volume    = {106},
  number    = {3},
  pages     = {527 - 546},
  issn      = {0304-405X},
  doi       = {https://doi.org/10.1016/j.jfineco.2012.06.005},
  abstract  = {Aggregate stock return volatility is both persistent and countercyclical. This paper tests whether it is possible to improve volatility forecasts at monthly and quarterly horizons by conditioning on additional macroeconomic variables. I find that several variables related to macroeconomic uncertainty, time-varying expected stock returns, and credit conditions Granger cause volatility. It is more difficult to find evidence that forecasts exploiting macroeconomic variables outperform a univariate benchmark out-of-sample. The most successful approaches involve simple combinations of individual forecasts. Predictive power associated with macroeconomic variables appears to concentrate around the onset of recessions.},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/Paye2012.pdf:PDF},
  keywords  = {Conditional volatility, Realized volatility, Granger causality, Forecast evaluation, Forecast combination},
  timestamp = {2018-05-19},
}

@Article{QiuSrinivasanStreet2006,
  author    = {Qiu, Xin Ying and Srinivasan, Padmini and Street, Nick},
  title     = {Exploring the Forecasting Potential of Company Annual Reports},
  journal   = {Proceedings of the American Society for Information Science and Technology},
  year      = {2006},
  volume    = {43},
  number    = {1},
  pages     = {1-15},
  doi       = {10.1002/meet.14504301168},
  abstract  = {Previous research indicates that the narration disclosure in company annual reports can be used to assist in assessing the company's short‐term financial prospects. However, not much effort has been made to systematically and automatically assess the predictive potential of such reports using text classification, information retrieval, and machine learning techniques. In this study, we built SVM‐based predictive models with different feature selection methods from ten years of annual reports of 30 companies. We used feature selection methods to reduce the term space and studied the class‐related vocabulary. Evaluation of predictive accuracy is performed with cross validation and t‐test significance tests. We compare different models' performance and analyze misclassification rates by year and by industry. We identify the strengths and weaknesses of each model. Our results support the feasibility of automatically predicting next‐year company financial performance from the current year's report. We suggest text features can be further studied to understand their roles as indicators of company's future performance. This research paves the way for large‐scale automatic analysis of the relationship between annual reports and short‐term performance, as well as the identification of interesting signals within annual reports.},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/QiuSrinivasanStreet2006_2.pdf:PDF;:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/QiuSrinivasanStreet2006.pdf:PDF},
  timestamp = {2018-05-19},
}

@Article{Feldman_et_al_2010,
  author    = {Feldman, Ronen and Govindaraj, Suresh and Livnat, Joshua and Segal, Benjamin},
  title     = {Management's tone change, post earnings announcement drift and accruals},
  journal   = {Review of Accounting Studies},
  year      = {2010},
  volume    = {15},
  number    = {4},
  pages     = {915--953},
  issn      = {1573-7136},
  doi       = {10.1007/s11142-009-9111-x},
  abstract  = {This study explores whether the management discussion and analysis (MD{\&}A) section of Forms 10-Q and 10-K has incremental information content beyond financial measures such as earnings surprises and accruals. It uses a classification scheme of words into positive and negative categories to measure the tone change in the MD{\&}A section relative to prior periodic SEC filings. Our results indicate that short window market reactions around the SEC filing are significantly associated with the tone change of the MD{\&}A section, even after controlling for accruals and earnings surprises. We show that management's tone change adds significantly to portfolio drift returns in the window of 2 days after the SEC filing date through 1 day after the subsequent quarter's preliminary earnings announcement, beyond financial information conveyed by accruals and earnings surprises. The drift returns are affected by the ability of the tone change signals to help predict the subsequent quarter's earnings surprise but cannot be completely attributed to this ability. We also find that the incremental information of management's tone change depends on the strength of the firm's information environment.},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/Feldman_et_al_2010.pdf:PDF;:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/FeldmanGovindarajLivnatSegal2008.pdf:PDF},
  timestamp = {2018-05-19},
}

@Online{TIME_2012,
  author       = {Belsky, Gary},
  title        = {Why Text Mining May Be The Next Big Thing},
  year         = {2013},
  date         = {2012-03-20},
  url          = {http://business.time.com/2012/03/20/why-text-mining-may-be-the-next-big-thing/},
  organization = {TIME},
  urldate      = {2018-05-19},
  timestamp    = {2018-05-19},
}

@Online{Raviv_online,
  author    = {Eran Raviv},
  title     = {Intraday volatility measures},
  date      = {2012-09-08},
  url       = {https://eranraviv.com/intraday-volatility-measures/},
  urldate   = {2018-05-21},
  timestamp = {2018-05-21},
}

@InBook{ViolanteLaurent2012,
  author    = {Violante, Francesco and Laurent, Sébastien},
  title     = {Volatility Forecasts Evaluation and Comparison},
  booktitle = {Handbook of Volatility Models and Their Applications},
  year      = {2012},
  publisher = {Wiley-Blackwell},
  isbn      = {9781118272039},
  chapter   = {Nineteen},
  pages     = {465-486},
  doi       = {10.1002/9781118272039.ch19},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/ViolanteLaurent2012.pdf:PDF},
  keywords  = {volatility forecasts, evaluation and comparison, loss functions, latent variable problems, consistency of ordering, inference on forecast performances},
  timestamp = {2018-05-22},
}

@InBook{PattonSheppard2009,
  author    = {Patton, Andrew J. and Sheppard, Kevin},
  title     = {Evaluating Volatility and Correlation Forecasts},
  booktitle = {Handbook of Financial Time Series},
  year      = {2009},
  editor    = {Mikosch, Thomas and Krei{\ss}, Jens-Peter and Davis, Richard A. and Andersen, Torben Gustav},
  publisher = {Springer Berlin Heidelberg},
  isbn      = {978-3-540-71297-8},
  pages     = {801--838},
  doi       = {10.1007/978-3-540-71297-8_36},
  abstract  = {This chapter considers the problems of evaluation and comparison of volatility forecasts, both univariate (variance) and multivariate (covariance matrix and/or correlation). We pay explicit attention to the fact that the object of interest in these applications is unobservable, even ex post, and so the evaluation and comparison of volatility forecasts often rely on the use of a ``volatility proxy'', i.e. an observable variable that is related to the latent variable of interest. We focus on methods that are robust to the presence of measurement error in the volatility proxy, and to the conditional distribution of returns.},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/PattonSheppard2009.pdf:PDF},
  timestamp = {2018-05-22},
}

@Article{HuangLi2011,
  author    = {Huang, Ke-Wei and Li, Zhuolun},
  title     = {A Multilabel Text Classification Algorithm for Labeling Risk Factors in SEC Form 10-K},
  journal   = {ACM Transactions on Management Information Systems (TMIS)},
  year      = {2008},
  volume    = {2},
  number    = {3},
  pages     = {18:1--18:19},
  issn      = {2158-656X},
  doi       = {10.1145/2019618.2019624},
  url       = {http://doi.acm.org/10.1145/2019618.2019624},
  abstract  = {This study develops, implements, and evaluates a multilabel text classification algorithm called the multilabel categorical K-nearest neighbor (ML-CKNN). The proposed algorithm is designed to automatically identify 25 types of risk factors with specific meanings reported in Section 1A of SEC form 10-K. The idea of ML-CKNN is to compute a categorical similarity score for each label by the K-nearest neighbors in that category. ML-CKNN is tailored to achieve the goal of extracting risk factors from 10Ks. The proposed algorithm can perfectly classify 74.94% of risk factors and 98.75% of labels. Moreover, ML-CKNN is empirically shown to outperform ML-KNN and other multilabel algorithms. The extracted risk factors could be valuable to empirical studies in accounting or finance.},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/HuangLi2011.pdf:PDF},
  keywords  = {Text classification, annual reports, multilabel classification, risk factors, text mining},
  numpages  = {19},
  timestamp = {2018-05-27},
}

@InProceedings{HeidariFelden_Footnotes_2015,
  author    = {Heidari, Maryam and Felden, Carsten},
  title     = {Impact of Text Mining Application on Financial Footnotes Analysis},
  booktitle = {New Horizons in Design Science: Broadening the Research Agenda},
  year      = {2015},
  editor    = {Donnellan, Brian and Helfert, Markus and Kenneally, Jim and VanderMeer, Debra and Rothenberger, Marcus and Winter, Robert},
  publisher = {Springer International Publishing},
  isbn      = {978-3-319-18714-3},
  pages     = {463--470},
  abstract  = {In recent decade and with the advent of the eXtensible Business Reporting Language (XBRL), financial reports have a great mutation in terms of a unified reporting process. Nevertheless, the unstructured part of financial reports, so called footnotes, remains as barrier facing an accurate automatic and real-time financial analysis. The purpose of this paper is to investigate whether the text mining approach is an appropriate solution to assist analyzing textual financial footnotes or not. The implemented text mining prototype is able to classify textual financial footnotes into related pre-defined categories automatically. This avoids manually reading of the entire text. Different text classification supervised algorithms have been compared, where the decision tree by 90.65{\%} accuracy performs better rather than other deployed classifiers. This research provides preliminary insights about the impact of using a text mining approach on automatic financial footnote analysis in terms of saving time and increasing accuracy.},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/HeidariFelden.pdf:PDF},
  timestamp = {2018-05-27},
}

@Unpublished{Amel-Zadeh_Faasse_2016,
  author    = {Amel-Zadeh, Amir and Faasse, Jonathan},
  title     = {The Information Content of 10-K Narratives: Comparing MD\&A and Footnotes Disclosures},
  year      = {2016},
  note      = {Working Paper, available under \url{https://www.wiwi.hu-berlin.de/de/professuren/bwl/cofi/seminars/16w/amel-zadeh_2016.pdf} (visited on 05/27/2018)},
  url       = {https://www.wiwi.hu-berlin.de/de/professuren/bwl/cofi/seminars/16w/amel-zadeh_2016.pdf},
  urldate   = {2018-05-27},
  abstract  = {This paper examines the characteristics and variations within firms’ 10-K filings over a 20 year time period. We find that investors’ reaction to textual characteristics of the MD&A in 10-Ks is much stronger and more timely than their reaction to textual characteristics of the notes to the financial statements. Characteristics of the MD&A and footnotes are also predictive of future returns, volatility, and firm profitability. Our evidence suggests that investor pay limited attention to the footnotes compared to the MD&A and that firms exploit biases in investors’ information processing through their disclosure choices within 10-K filings.},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/Amel-Zadeh_Faasse_2016.pdf:PDF},
  timestamp = {2018-05-27},
}

@Article{ThinggaardJeppersenMadsen2016,
  author    = {Thinggaard, Frank and {S{\o}nderby Jeppesen}, Carsten and Madsen, Kasper},
  title     = {The Information Content of Note Disclosures and MD\&A Information in the Financial Report – A Study of Market Reactions in Denmark},
  journal   = {Ledelse \& Erhvervsoekonomi},
  year      = {2015},
  volume    = {79},
  number    = {4},
  pages     = {25--42},
  issn      = {0902-3704},
  url       = {https://www.djoef-forlag.dk/services/djm/ledelsedocs/2015/2015_4/DJoMB_vol79_no4_3.pdf},
  urldate   = {2018-05-27},
  abstract  = {The preparation of disclosures in the financial report constitutes a significant cost to most companies, but do the disclosures have information content to investors? This paper examines stock market reactions to the release of note disclosures and MD&A (management discussion and analysis) information. The study is based on data from the Danish capital market in 2006-2009 because here it is largely possible to isolate the release of such information from other information in the financial report. The primary results suggest that for some companies, note disclosures and information in the MD&A section are considered highly value-relevant by investors. However, for the majority of companies, investors do not immediately revise their expectations based on the disclosures. The response seems to depend on company specific factors.},
  day       = {31},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/ThinggaardJeppersenMadsen2016.pdf:PDF},
  keywords  = {disclosures, notes, management commentary, financial report, information content, event study},
  publisher = {DJ{\O}F forlag},
}

@MastersThesis{Bacher2012,
  author      = {Bacher, Simon},
  title       = {Mining Unstructured Financial News to Forecast Intraday Stock Price Movements},
  institution = {University of Mannheim},
  year        = {2012},
  type        = {mathesis},
  file        = {:Bacher2012.pdf:PDF},
  timestamp   = {2018-05-27},
}

@Article{KearneyLiu2014,
  author    = {Kearney, Colm and Liu, Sha},
  title     = {Textual sentiment in finance: A survey of methods and models},
  journal   = {International Review of Financial Analysis},
  year      = {2014},
  volume    = {33},
  pages     = {171 - 185},
  doi       = {https://doi.org/10.1016/j.irfa.2014.02.006},
  abstract  = {We survey the textual sentiment literature, comparing and contrasting the various information sources, content analysis methods, and empirical models that have been used to date. We summarize the important and influential findings about how textual sentiment impacts on individual, firm-level and market-level behavior and performance, and vice versa. We point to what is agreed and what remains controversial. Promising directions for future research are emerging from the availability of more accurate and efficient sentiment measures resulting from increasingly sophisticated textual content analysis coupled with more extensive field-specific dictionaries. This is enabling more wide-ranging studies that use increasingly sophisticated models to help us better understand behavioral finance patterns across individuals, institutions and markets.},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/KearneyLiu2014.pdf:PDF},
  keywords  = {Behavioral finance, Textual sentiment, Internet messages, News, Market efficiency},
  timestamp = {2018-05-27},
}

@Article{GuoShiTu2017,
  author    = {Guo, Li and Shi, Feng and Tu, Jun},
  title     = {Textual analysis and machine leaning: Crack unstructured data in finance and accounting},
  journal   = {The Journal of Finance and Data Science},
  year      = {2016},
  volume    = {2},
  number    = {3},
  pages     = {153 -- 170},
  issn      = {2405-9188},
  doi       = {https://doi.org/10.1016/j.jfds.2017.02.001},
  url       = {http://www.sciencedirect.com/science/article/pii/S2405918816300496},
  urldate   = {2018-05-27},
  abstract  = {In finance and accounting, relative to quantitative methods traditionally used, textual analysis becomes popular recently despite of its substantially less precise manner. In an overview of the literature, we describe various methods used in textual analysis, especially machine learning. By comparing their classification performance, we find that neural network outperforms many other machine learning techniques in classifying news category. Moreover, we highlight that there are many challenges left for future development of textual analysis, such as identifying multiple objects within one single document.},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/GuoShiTu2017.pdf:PDF},
  keywords  = {Machine learning, Textual analysis, Finance, Accounting, Media news, Sentiment, Information},
  timestamp = {2018-05-27},
}

@Article{JonesKaulLipson_1994,
  author    = {Jones, Charles M. and Kaul, Gautam and Lipson, Marc L.},
  title     = {Transactions, Volume, and Volatility},
  journal   = {Review of Financial Studies},
  year      = {1994},
  volume    = {7},
  number    = {4},
  pages     = {631--651},
  abstract  = {We show that the positive volatility-volume relation documented by numerous researchers actually reflects the positive relation between volatility and the number of transactions. Thus, it is the occurrence of transactions per se, and not their size, that generates volatility; trade size has no information beyond that contained in the frequency of transactions. Our results suggest that theoretical research needs to entertain scenarios in which (1) both the frequency and size of trades are endogenously determined, yet (2) the size of trades has no information content beyond that contained in the number of transactions. Article published by Oxford University Press on behalf of the Society for Financial Studies in its journal, The Review of Financial Studies.},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/JonesKaulLipson_1994.pdf:PDF},
  timestamp = {2018-07-24},
}

@Unpublished{Diebold_Book_2017,
  author    = {Diebold, Francis X.},
  title     = {Forecasting in Economics, Business, Finance and Beyond},
  year      = {2017},
  note      = {Department of Economics, University of Pennsylvania. Available under \url{http://www.ssc.upenn.edu/~fdiebold/Textbooks.html} (visited on 07/24/2018)},
  url       = {http://www.ssc.upenn.edu/~fdiebold/Textbooks.html},
  urldate   = {2018-07-24},
  file      = {:/Users/kevin/Dropbox/Master_Thesis/Text_mining_literature/DIEBOLD_2017.pdf:PDF},
  timestamp = {2018-07-24},
}

@Comment{jabref-meta: databaseType:biblatex;}
