\section{Results}
\label{sec: results}
This section will display empirical results for the uni- and multivariate analyses on the 10-K* corpus presented in the previous section \ref{sec: data_sample}. Additionally, a brief analysis of a basic MZ-regression of \texttt{PFRV} versus \texttt{PreFRV} will be shown. Finally, linear regression results in a multivariate setting for the two model specifications and three training split methodologies will be discussed. 

% ----------------------------------------------------------- %

\subsection{Univariate Analysis}
\label{ssec: results_univariate}

\subsubsection{Pre- and Post-Filing Realized Volatility}
\label{sssec: results_correls_mz}

As a starting point, I will consider an univariate analysis, which aims to test the accuracy of a simple time-series baseline: it shall be evaluated how well the level of volatility just \textit{before} the filing is submitted is able to explain the value of volatility \textit{post}-filing. Table \ref{tab: COR_VOLAS} displays the correlation coefficient of \texttt{PFRV} with \texttt{PreFRV} as well as other volatility measures, which will be used in robustness checks (see the Table footnote on the variable descriptions and the corresponding section in this work). As expected, the correlation between pre- and post-filing realized volatility is positive and highly significant in the cross section of 46,483 annual reports analysed. Figure \ref{fig: pfrv_vs_tsfc} extends the idea of correlation analysis and displays the scatterplot of \texttt{PFRV} versus \texttt{PrefRV} as well as the fitted MZ regression line. As it is observable, however, the goodness-of-fit is rather poor, although it seems mainly driven from outliers visible on the plot. A R-squared statistic of .34 confirms this observation and gives rise to call for an extended model with more control variables, which should be better able to capture cross-sectional variation of weekly realized volatility after the filing of a 10-K* report. In addition to the scattermatrix, Figure \ref{fig: pfrv_vs_tsfc} also displays the marginal distribution of \texttt{PFRV} and \texttt{PreFRV} (see the blue-shaded histograms along the axes). Both variables follow a bell-shaped distribution in their logarithmic form. This observation with regards to the distribution of volatility in the cross section of firms was already evidenced in \textcite{Kogan2009_1, TsaiWang2012, TsaiWang2013, TsaiWang2016}. Therefore, logarithmic versions of the volatility measures will be used for the multivariate analysis as well. 
%Correlations between logarithmic versions of volatility are comparable to the \enquote{raw} values (cf. Table \ref{tab: pfrv_tsfc}). All correlation coefficients are highly significant with p-values being below .001 for the full sample size with 46,483 observations. 
Additionally, Figure \ref{fig: delta_histos_pfrv_vs_tsfc} shows the forecast error of the \enquote{auto-regressive} model in realized volatility (i.e., using pre-filing realized volatility to predict post-filing realized volatility). The delta series distribution is bell-shaped, almost symmetric (skewness: -.065) and slightly leptokurtic (kurtosis: 4.94). The inspection of the forecast error moreover reveals that on an aggregated delta between pre- and post-filing realized stock return volatility is negligibly small (median forecast error: .07 percentage point, mean forecast error:  .2502 percentage points), yet indicates that \texttt{PreFRV} slightly overestimates \texttt{PFRV}. 

%As already indicated in section \ref{ssec: data_sample_desc-stats-variables}, the two time-series models seem overly prudent, producing estimates that on average exceed \texttt{PFRV}. This is confirmed by statistics: the average (median) delta is 3.26 (2.62) percentage points for the GARCH and 2.90 (2.41) percentage points for the GJR-GARCH. 

\subsubsection{Correlation Analysis}
\label{sssec: results_correls_rhs}
Continuing the univariate analysis, I seek to explore how both text-related and control variables correlate with post-10-K*-filing stock return volatility. Table \ref{tab: cormat_pfrv_all_RHS} shows the correlation matrix for all variables used in this thesis; the lower triangular (including the main diagonal) of the matrix displays Pearson coefficients, while the upper triangular is filled with the corresponding p-values to test for significance.

Again, it needs to be pointed out that correlation coefficients and p-values are estimated from the whole sample. This constitutes a factor of special importance for the textual variables, which theoretically require a sample split into in- and out-of-sample fraction, but are computed on a full-sample basis so as to ensure comparability as well as a sufficiently large number of observations. The correlation coefficients of \texttt{NEG\_SENT}, \texttt{UNCERT}, and \texttt{LITI} with \texttt{PFRV} are positive and significant and thus seem to confirm hypotheses 1, 4, and 5, respectively. However, the three variable correlate among each other as well, to some extent potentially reflecting the overlap in the three word lists. Similarly, hypothesis 7 seems confirmed on an univariate basis, namely that higher focus of financial topics coincides with cases of lower post-filing realized volatility. However, hypothesis 3 appears to be rejected by the correlation analysis, as reports in more assertive language seem to induce larger \texttt{PFRV}. A potential explanation might read as follows: assertiveness per se might be neither positive nor negative. Thus, the fact that the management applies language of conviction might simply be an \textit{amplifier} that helps market participants to interpret the signals conveyed in the 10-K*, be it positive or negative ones. Hence, the \enquote{relevance} of news might, ceteris paribus, appear large and thus induce trading activity and potentially increase volatility (equally so for both positive and negative news). Moreover, relating to hypothesis 2 and positive sentiment, the positive correlation coefficient with \texttt{PFRV} might very likely stem from the missing consideration of negation phrases surrounding the positive words\footnote{This alternative hypothesis seems to be supported by the high and significant positive correlation (.58) between \texttt{NEG\_SENT} and \texttt{POS\_SENT}.}. Also, in contrast to expectations, longer reports (i.e., larger \texttt{GFS}) on an univariate basis seem to correlate with lower \texttt{PFRV}, giving rise to the conjecture that the management obfuscation theory provided in \textcite{Li2008} might hold true in the available sample; i.e., the filing company might indeed succeed to disguise bad news by applying verbose language and producing long reports.

With regards to the control variables, all relationships except \texttt{TRVOL} and \texttt{LEVER} are as expected: smaller firms and firms with larger book-to-market ratio are, ceteris paribus, more risky. The latter, although significant, is however small in absolute magnitude. Surprisingly, and contradictory to previous findings, firms with large trading volume before the filing and a higher degree of leverage appear to co-occur with \textit{lower} \texttt{PFRV} on a weekly horizon for the sample at hand\footnote{Note that for \texttt{TRVOL} the result might be due to the timing difference related to the variable construction; while \texttt{PFRV} measures volatility \textit{post}-filing, \texttt{TVOL} represents the median number of shares traded \textit{pre}-filing. If any positive relationship between volume and volatility were to hold, it would likely occur if the variables are measured concurrently. Indeed, one needs to acknowledge that trading volume is very likely to behave differently pre- and post-filing, especially on a weekly horizon. However, for this thesis all independent variables were constructed in such fashion that they are \textit{known} to the investor before the filing, making the volatility prediction in fact a forecasting task.}. Moreover, market-wide volatility (\texttt{VIX}) seems to spill-over to company-level realized volatility post filing (correlation of .29 with \texttt{PFRV}).

% ----------------------------------------------------------- %

\subsection{Multivariate Analysis and Regression Results}
\label{ssec: results_multivariate}
In this section, the analysis will be extended to a multivariate setting and report OLS estimation results for equation \eqref{eq: linear_reg}. Overall, five annual augmented MZ-regressions (2013-2017) were estimated in three different scenarios, each one representing on of the three specifications for the sample splitting methodology (i.e., static, rolling, and extending \texttt{VIBTW} weight training window, respectively). 

Table \ref{tab: CB_MZ_static} reports the results for the static weight estimation window. Surprisingly, goodness-of-fit increases for regressions till 2015 and then starts to decrease again, although the weight estimation window is static. However, as sentiment scores are significant only in a few cases, this performance discrepancies are very likely to stem from the non-textual variables included in the linear model. As expected, the coefficient related to \texttt{PreFRV} forecast is highly significant and positive in the multivariate MZ-regression setting as well. With respect to the textual variables, negative sentiment increases \texttt{PFRV} significantly in all five out-of-sample years available for testing. For positive sentiment, the multivariate analysis confirms the findings from correlation analysis: post-filing realized volatility \textit{increases} with \texttt{POS\_SENT}, and this is - as for negative sentiment - the case for all five out-of-sample years. These results indicate that positive sentiment actually might be a hidden version of negative sentiment, with bad news being disguised by negated versions of otherwise positive phrases. However, with respect to the other hypotheses, assertiveness and uncertainty in the writing style of the 10-K* filing do not seem to affect \texttt{PFRV}, while litigious language seems to do so only in the latter period of the testing sample (2016 and 2017). Readability and intensity of financial terms are significantly different from zero only in single specifications (i.e., the MZ-regression in 2015 and 2013, respectively). With respect to readability, the positive coefficient attached to \texttt{GFS} thus at least for one year confirms hypothesis 6 (yet contradicts the univariate analysis) and implies - on ten percent significance level - that longer and thereby less readable reports increase realized volatility in the week after the filing. As indicated, and regarding financial focus in the text, hypothesis 7 is confirmed: usage of figures, ratios, percentages, monetary keywords, etc. decreases \texttt{PFRV} as investors perceive the news in the 10-K* as less informative. However, the statistical evidence being present only in one out of five years available for testing weakens the relative importance of these variables, especially when compared to the strong significance of negative and (potentially false) positive tonality.

With respect to the control variables, one can conclude that large companies, firms with low financial leverage  as well as firms with low book-to-market ratio are, ceteris paribus, perceived as less risky, implying lower \texttt{PFRV}. For trading volume the results are insignificant in the first testing year (2013) and then turn significantly positive for 2014-2017. For \texttt{VIX}, the results are ambiguous: for 2013, the estimation reveals the apparently paradoxical relation of decreasing firm-level volatility when markets are turbulent. For the middle part of the test sample at hand (2014 - 2016) no significant impact of market-level volatility on firm-specific \texttt{PFRV} is found, with the relation turning to the (expected) positive co-movement in 2017. 

%Table \ref{tab: B1_MZ_gjr} displays the same analysis using the GJR-GARCH(1,1). The results for the static training window are virtually identical to those of the GARCH, with predictive accuracy being marginally lower as indicated by adjusted R-square measures. One difference worth highlighting is the slight increase in significance of \texttt{NEG\_SENT} and \texttt{POS\_SENT}, implying that in an asymmetric-shock capturing time-series model, the changes in \texttt{PFRV} might be better explained by 10-K* textual content. 

Table \ref{tab: CB_MZ_rolling} shows the regression estimates for the rolling \texttt{VIBTW} estimation window, while Table \ref{tab: CB_MZ_extending} does so for the extending training window. The results are almost equivalent to the static window, indicating that the choice of the weight estimation window is not of crucial importance over the time horizon of multiple years. For all textual variables the results are close to identical for all specifications, i.e., significance as well as positive coefficients for negative and positive sentiment as well as punctual significance for assertive, uncertain and litigious language as well as readability and usage of financial terminology. 

As an alternative to running five separate annual MZ-regression, one can also regress all out-of-sample observations in a single, pooled linear model. This specification is considered in robustness checks when different term weighting schemes are compared; the results are presented in Table \ref{tab: C_MZ_regression_pooled}. Anticipating the results presented therein, the coefficients associated with 10-K* language are both qualitatively and quantitatively similar to the estimates for annual regression presented in this section. In addition, Table \ref{tab: PreFRV_stepwise_regression} presents pooled OLS estimates that compare coefficient estimates after the addition / deletion of textual variables rather than across different weighting schemes. For what concerns positive, negative, and litigious language, the coefficients are significant and positive regardless of the inclusion of the other text variables. Especially worth-mentioning is the change in the coefficient of \texttt{NEG\_SENT} after positive sentiment is included; indeed, the coefficient declines, indicating that \texttt{POS\_SENT} is in fact a hidden version of negative tonality and \enquote{soaks up} variation in \texttt{PFRV}. A similar picture is obtained as soon as \texttt{LITI} is added, as coefficients of both positive and negative sentiment decline. This observation might point towards collinearity between those three variables, as all three might in fact be rephrased versions of \enquote{bad news}. With regards to the usage of litigious sentiment words, it is necessary to highlight that significance in the pooled OLS estimates is likely to stem from the past two years in the test sample (i.e., 2016 and 2017), as those were the only years that corroborated the significant findings also in the five annual MZ regressions. Finally, the results of the stepwise addition of textual coefficients also reveal that readability (\texttt{GFS}) is only significant when financial keyword intensity is not included in the model.

All in all it can be said that the results across different regression variants are very similar and point towards a common conclusion: when using past volatility, which was proven to be a good predictor for current/future volatility, in combination with common control variables such as VIX-level, the firm's size, leverage, and book-to-market ratio, or the trading volume of the stock, these variables already capture a majority of variation in post-filing realized volatility. Textual content of the 10-K* seems to improve predictive accuracy considerably and consistently only for the positive and negative dimensions of language. Other, \enquote{finer} facets of text (like assertiveness versus uncertainty, or readability) fall short in providing value added in predicting realized volatility in the week after the filing was submitted, or do so only for specific years of the test sample and/or a specific choice of the training window size. Although the overall goodness-of-fit of the different models would display potential for improvement, the latter does not seem to stem from the textual sentiment embedded in the filing. Two potential explanations for the insignificant results for the five text variables other than positive and negative tonality could be a poor performance of the \texttt{VIBTW}-scheme or a mis-measurement of the chosen volatility proxy. The next section is, among one other test performed, devoted to test result robustness by addressing exactly these two ideas.

\clearpage