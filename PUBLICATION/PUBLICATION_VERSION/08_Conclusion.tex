\section{Conclusions}
\label{sec: conclusion}
Being a variable of interest for both academia and practical application, volatility forecasting is a complex undergoing with many factors to consider. Besides classical time-series models, which -- due to the auto-regressive nature of return volatility -- appear to be the main driver of realized volatility even after corporate filing releases (such as 10-K* submissions), many researchers attempted to find innovative methods to include further explanatory variable that assist in explaining post-filing volatility. This thesis contributes to this particular stream of literature by analyzing textual contents in corporate filings. On the basis of \textcite{Jegadeesh2013}, market-based term weighting of 10-K* text content was transferred to the field of volatility modelling: using past observations of realized volatility after the submission of a 10-K*, sentiment word counts are smoothed on the basis of the impact that specific word had on volatility. The learned smoothing factors, called volatility-impact based term weights (\texttt{VIBTW}) were then applied to out-of-sample term counts for \enquote{newly} filed 10-K* reports. The weighted term schemes were then -- in an aggregated manner -- used in augmented MZ regressions in order to test whether textual features such as tone or readability can provide incremental value to conventional models.

However, the main results of the estimations seem to resemble a well-known stylized fact in empirical finance: while equity returns still seem to unpredictable, return volatility -- at least to some extent -- can be explained (especially by deploying established time-series methods). In this line of thought, the equity return puzzle seems to be more \enquote{open} for improvements coming from the world of textual analysis (if term weighting is derived from past realizations of (abnormal) returns). Yet, based on sentiment word lists from \textcite{Loughran2011, Loughran2014} and a sample of 46,483 10-K* filings, this work finds a significant relationship between post-filing realized volatility for negative and positive tonality embedded in annual reports. Other text-related variables, such as assertiveness, uncertainty, litigiousness, focus on financial terminology, or readability seem to play an insignificant role in the augmented MZ regressions which were estimated -- therefore leaving the majority of variance in realized volatility in the cross section to be explained by known factors. Regarding the latter, a robustness check that takes use of two models firmly established in the volatility literature, revealed that the by far most important model inputs are time-series model forecasts such as the GARCH and the GJR-extension thereof. These factors are accompanied by established control variables, such as the level of the VIX, firm size, leverage, trading volume, and book-to-market ratio. These findings are robust in terms of how one chooses to proxy unobservable post-filing volatility: squared and absolute returns confirm the results that were obtained using realized volatility, implying that the construction of the volatility variable does not seem to play a role when determining the impact of quantitative and qualitative inputs: Similarly, the findings are also robust with regards to the choice of the term-weighting scheme. In great part, the results derived from a market-based term smoothing (\texttt{VIBTW}) are confirmed by established methodologies such as \texttt{TFIDF} or \texttt{WFIDF}, or are even superseded by the newly introduced \texttt{VIBTW}. 

However, although this thesis contributing to an ever growing body of literature of text analysis in finance and accounting, it is worth highlighting that this field of research is still \enquote{young} and leaves room for improvement. The most obvious extension is that future contributions might consider corpora that are not exclusively in English language. Especially for the business domain, foreign languages still lag behind with the presence of extensive dictionaries or sentiment word lists, thereby leaving large room for prospective contributions. 

Moreover, with respect to the textual underlying used for sentiment analysis in this work, 10-K* present one of the most important inputs for text analysis in the finance and accounting domain. At the same time, one needs to acknowledge one key shortcoming of this corpus, which -- unfortunately -- can not be circumvented: any annual report is a description about a company's \textit{past} fiscal year. Although there are requirements which force the management to include forward-looking statements in the 10-K* as well (such as the mentioned Item 7, i.e., the so-called MD\&A section), a large part of text is still reflecting past occurrences and results. This ultimately raises the question whether the tone extracted from such a filing is suitable for the attempt to explain market variables in the future. 

Recognizing this unavoidable disadvantage related to the 10-K* corpus, there are, however, potential improvements to the methodologies applied in this thesis. Hence, I will provide some impulses for future research and present potential alternative research specifications. A first and feasible starting point regards the choice of the post-event window (labelled $\tau$ in equation \eqref{eq: pfrv-definition}). In other words, instead of considering realized volatility in the \textit{week} after the 10-K* filing date, variations might apply monthly (e.g. \textcite{Jegadeesh2013}), quarterly (e.g., \textcite{Rekabsaz2017}) or annual (e.g., \textcite{Loughran2011}) volatility measures instead.

Another promising specification might be to follow \textcite{Nizer_BovespaVola_2012}, who\enquote{revert} the idea presented in this thesis: instead of using classified text content (i.e., sentiment) to explain volatility, the authors propose that \enquote{abnormal} volatility might be a means of its own that helps to categorize news (or in the context of this work: a 10-K*) as important/informative. Abnormality of volatility is measured by the forecast error: \enquote{a way to evaluate the news' importance is by the error (difference) between a volatility model and the effective volatility} \parencite[10675]{Nizer_BovespaVola_2012}.  In the project at hand this could be defined as a delta series of the post- and pre-filing realized volatility (i.e., \texttt{PFRV} minus \texttt{PreFRV}). Also the forecasts derived from the (GJR-)GARCH model could be used to compute the relevant error series. As another potential variant, one might also define abnormality as a post-filing volatility level that deviates from an average level of volatility observed in a pre-defined past time horizon (such as one year).

Furthermore, in the field of volatility prediction one often makes use of concepts like absolute returns or squared returns, which in turn implies that the \emph{direction} of the stock price movement per se does not matter. This leaves the additional possibility for future research to conduct sentiment analysis in a modified fashion: instead of categorizing sentiment into \enquote{buckets} such as negative, positive, uncertain, etc. tone, one might alternatively realize that it is not necessarily the type of sentiment that influences post-filing volatility, but rather the sheer presence of sentiment (of any kind). In other words, corporate filings in this context need not be classified as positive, negative, assertive, and so on --  it would be sufficient to find a measure that classifies the textual content as stock price \textit{relevant} versus stock price \textit{irrelevant}. In such a setting, one would \enquote{merely} care whether the textual sentiment of an annual report will affect the stock return, regardless in which direction the price change occurs. However, this would call for a modified and cautious definition of the document's \enquote{sentiment} score, which in this case might be instead called \enquote{relevance} score: ignoring context and simply summing up sentiment word counts in such a setting \textit{might} lead to the effect of \textcite{cancelling out} of tone-opposing frequencies (e.g., one positive and one negative statement could potentially be either two relevant entries (unconnected statements) or instead zero relevant entries (with, for instance, the positive statement attenuating the relevance of the negative statement -- or vice versa)).

Yet another potential extension of the presented analysis is to consider \textit{changes} in sentiment instead of \textit{levels}, that is conduct research on the basis of first differences in sentiment scores (or term counts). In this context, \textcite[1220]{LM-meta-2016} point out: \enquote{when document tone is differenced, the importance of Zipf’s law is mitigated. Zipf’s law applies to levels, but the distribution of changes in tone can be driven by numerous words that are not the most frequently occurring overall words}. However, as \textcite{Loughran2011} indicated, \enquote{The differencing method also assumes that a reader can remember the frequency of negative words in previous news articles, columns, or 10-Ks -- for example, that today’s column or 10-K has fewer negative words than previous editions, so it may convey a bullish signal.} A good starting point for analysis pointing in this direction are the papers of \textcite{Loughran2011, Feldman_et_al_2010}. 

\clearpage