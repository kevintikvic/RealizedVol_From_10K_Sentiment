\section{Research Framework: Cross-Sectional Volatility Model}
\label{sec: volamodel}

In this section I will present the second pillar of the research design of this work. It deals with the usage of the sentiment scores calculated in the previous section \ref{sec: sentiment_calcs} for out-of-sample volatility prediction purposes, embedded in a set of seven research hypotheses. Moreover, one key model input is introduced: resembling the idea of volatility clustering and persistence, pre-filing realized volatility will be used as a predictive variable. In addition, control variables and their construction are presented. Finally, the model specification is explained in further detail.

% ----------------------------------------------------------- %

\subsection{Pre-Filing Realized Volatility as Predictive Variable}
\label{ssec: volamodel_timeseries}
Before relating \texttt{PFRV} to the qualitative variables extracted from 10-K* text, it is important to highlight the most \enquote{influential} right-hand side variable that will be used in the models. It is known from empirical literature that return volatility (or more generally, squared or absolute returns) is highly persistent, especially if sampled from longer frequencies. Following \textcite{Kogan2009_1, TsaiWang2016, Rekabsaz2017}, who all used past volatility as a baseline predictor for post-10-K-filing volatility, I will use pre-filing realized volatility as a predictor in all models. \textcite[275]{Kogan2009_1} in that context highlight that \enquote{Volatility is, generally speaking, not constant, yet prior volatility \textelp{} is a very good predictor of future volatility}. This resembles a very basic \enquote{auto-regressive} model in realized volatility; obviously, however, with an abuse of terminology, as the analysis is performed on the cross-section of 10-K* filings. Pre-filing realized volatility will be measured in the same manner as its ex-post counterpart (i.e., using the natural logarithm of the in-sample standard deviation as in equation \eqref{eq: pfrv-definition}), with the modification of $s = t-5$ and $\tau = t-1$ so as to capture volatility in the week \textit{before} the filing. In tabulations and the result analysis further on, pre-filing realized volatility will accordingly abbreviated with the variable name \texttt{PreFRV}. 

%Therefore, exploring the power of time-series models that embed auto-regressive nature, I will include as main explanatory variable for \texttt{PFRV} the one-week ahead forecast produced by two conventional models for conditional variance: the models of choice are the GARCH(1,1) and the GJR-GARCH(1,1), whereas coefficients were estimated on weekly return data from one year prior to the filing date (or, alternatively, the maximum number of weekly data available, if this number is smaller than 52)\footnote{The main motivation for the choice of these two models is to have both one symmetric and one asymmetric model; GARCH(1,1) and GJR-GARCH(1,1) have proven to be parsimonious yet effective and hard-to-beat benchmarks (e.g., also considered in \textcite{AntweilerFrank2004} and \textcite{HansenLunde}).}. I will call the corresponding variable \enquote{time-series forecast} and accordingly I will abbreviate it as \texttt{TS\_FC}\footnote{It shall be highlighted that in robustness checks (cf. section \ref{sec: robustness}) I will use the \texttt{TS\_FC} notation for an additional model specification, which replaces (GJR-) GARCH by the \textit{pre}-filing realized volatility.}.

With respect to the motivation of including a quantitative \enquote{time-series}-like forecast into a predictive model, \textcite{Rekabsaz2017} show that volatility models which incorporate both quantitative and qualitative information from 10-K* reports carry the most explanatory power (compared to benchmark models that use either of the two sources separately). Indeed, the main research interest of this thesis is not exclusively focussed on the question whether text embedded in corporate filings provides value for volatility prediction purposes; rather, I seek to investigate whether textual sentiment provides value \textit{added}, i.e., offers incremental value when used in addition to a historical quantitative predictor. 
%In this context, I want to explore whether textual contents contained in annual reports can provide marginal power in explaining the performance as well as forecast error of widely-used time-series models in a cross-sectional setting. 

\subsection{Hypotheses Development: Connecting 10-K* Text to Realized Volatility}
\label{ssec: volamodel_vola+senti}
As indicated in section \ref{sec: sentiment_calcs}, the main approach of incorporating 10-K* sentiment into volatility prediction is to learn term weights on the basis of past volatility impact from a training set of 10-K*s, and apply those weights to term frequencies of words contained in a LM-dictionary that is intended to measure sentiment in a particular category. The combination of term frequencies of words from sentiment \enquote{class} $k$ in an out-of-sample filing with their corresponding class-$k$ weights learned from the training sample $N_1$ will lead to the creation of a $k$-related sentiment measure, which is designed to extract a specific aspect in the management's writing style and potentially be connected to \texttt{PFRV}. Therefore, with respect to the textual analysis, I present the following seven hypotheses about how textual information embedded in annual reports is related to post-filing volatility.

\cbox[light_gray]{H1: Negative sentiment (\texttt{NEG\_SENT}) embedded in 10-K*s, reflected by higher $S_i^N(\texttt{VIBTW})$, is associated with higher \texttt{PFRV}.}

This hypothesis relates to \textcite{KothariLiShort_2009}, who were among the first to test textual impact on volatility. In a similar manner, I hypothesize that negative tone in corporate filings will lead market participants to perceive the filing company as more risky, implying, ceteris paribus, an increase in the post-filing volatility of stock returns. 

\cbox[light_gray]{H2: Positive sentiment (\texttt{POS\_SENT}) embedded in 10-K*s, and measured by $S_i^P(\texttt{VIBTW})$, is associated with \texttt{PFRV}.}

Following the findings of \textcite{KothariLiShort_2009}, who find that positive tonality in news disclosure by management, analysts, and business press decrease quarterly volatility after the release of such information, I hypothesize that a similar relationship holds for weekly post-filing volatility and sentiment contained in 10-K* filings. However, as indicated in section \ref{ssec: DTM_dimensionality}, the interpretation of coefficients assigned to \texttt{POS\_SENT} requires increased awareness and carefulness: as potential negation of positive phrases is neglected, \texttt{POS\_SENT} in fact might be negative sentiment which is formulated using negated positive terminology\footnote{In their meta study on textual analysis in finance, \textcite{LM-meta-2016} even suggest that \enquote{Unless a study can convincingly resolve the problems of negation, positive sentiment is best left untested} \parencite[1217]{LM-meta-2016} and, therefore included them in their 2011 study \enquote{more in the interest of symmetry} \parencite[45]{Loughran2011}.}. This would imply that \texttt{PFRV} would, ceteris paribus, increase for filings with larger degree of positive sentiment, thereby potentially resembling results in \textcite{AntweilerFrank2004}, who evidenced bullishness in message boards to lead to larger volatility after the message was posted. Therefore, no prediction will be made on the sign of the relation between positive sentiment and post-filing volatility. 

\cbox[light_gray]{H3: Assertiveness (\texttt{ASSERT}) in the management's writing style, reflected by higher $S_i^{SM}(\texttt{VIBTW})$, is associated with lower \texttt{PFRV}.}

This hypothesis relates to \textcite{HuangZangZheng14}, who tested how the assertiveness in the textual part of analyst reports affected abnormal returns in the equity markets. As they document with reference to psychology literature, investors perceive assertive and confident communicators as \enquote{more accurate, competent, and credible} and thus assume that they \enquote{convey information signals with greater precision} \parencite[2157]{HuangZangZheng14}. Therefore, I hypothesize that market participants will perceive the filing company as less risky, if the management applies a higher degree of conviction and assertiveness in writing the annual report.

Regarding the measurement of assertive tone, I will follow \textcite{HuangZangZheng14} and use the strong modal sentiment list from LM as an indicator for assertive and persuasive language. 

\cbox[light_gray]{H4: Usage of language related to uncertainty (\texttt{UNCERT}) in the 10-K* filing, reflected by higher $S_i^{U}(\texttt{VIBTW})$, is associated with higher \texttt{PFRV}.}

In contrast to H3, I hypothesize that if tone in 10-K* documents indicates uncertainty, investors will be more alert and interpret the information conveyed in the filing more cautiously. This increased incertitude about the future performance of the company will affect their valuation, and thereby increase the risk perceived -- leading to larger \texttt{PFRV}. When creating their dictionaries, \textcite{Loughran2011} tested this relationship on data starting five days after the filing and covering the whole subsequent year. Indeed, they found a positive association between volatility and frequency of words from the uncertainty list. In this context, it remains to be tested whether this association is also evident in a shorter post-filing window as well as under usage of \texttt{VIBTW}-weighting schemes.

\cbox[light_gray]{H5: Litigious language (\texttt{LITI}) embedded in corporate filings, reflected by higher $S_i^{L}(\texttt{VIBTW})$, is associated with higher \texttt{PFRV}.}

Under the assumption that the management of the filing company uses the 10-K* filing to be precautionary and inform (or forewarn) investors about potential future lawsuits or required legal action, this increased uncertainty about future cash-flows related to such juridical incidents will negatively influence stock valuation and perception about risk/volatility (i.e., increase \texttt{PFRV}). As for the uncertainty word list, \textcite{Loughran2011} evidence this relationship for the post-filing year, excluding the first five days after the filing, leaving room to test the robustness of their findings in a shorter post-filing window and in combination with an alternative term-weighting scheme. 

\cbox[light_gray]{H6: Longer, and consequently less readable annual reports (measured by the natural logarithm of gross file size, \texttt{GFS}), are associated with higher \texttt{PFRV}.}

This hypothesis is motivated by deliberations in \textcite[1644]{Loughran2014} who state that \enquote{better written documents produce less ambiguity in valuation, as reflected by the lower price volatility of the stock in the period immediately following the filing.} Thereby, more readable filings are associated with greater certainty and hence can be viewed as logical opposite to H4 (uncertainty). 

\textcite[2157]{HuangZangZheng14} in their study using post-filing CAR, from a signal-versus-noise perspective, additionally highlight that \enquote{Longer annual reports are less readable and harder to process. Therefore, it is reasonable to assume that a more concise report is easier to process and likely to receive more attention than a longer report, resulting in a greater price reaction.} As the authors focus on returns rather than return volatility, it is unclear whether this idea can be extended to the latter. One could assume that a similar relation might hold  at least for trading volume, which in turn is often positively related to volatility, making the channel of cause and effect an indirect one. By this line of thought, short (and thus readable) 10-K*s would lead to enhanced trading activity and thereby \textit{higher} post-filing volatility. Vice versa, longer and less readable 10-K*s would imply lower trading activity and lower \texttt{PFRV}. 

Supporting this conjecture, and relating to the obfuscation theory provided in \textcite[221]{Li2008} and briefly described in section \ref{sssec: lit_rev_mining_readability}, one could also hypothesize that management tends to produce longer reports so as to dilute and hide bad news in the filing. If this attempt succeeds (i.e., the filing is indeed longer and less readable) the usage of inflated language could disguise negative news, thereby inducing lower \texttt{PFRV}. This explanation, however, lacks to cover cases in which report size does not coincide with the presence of bad news (e.g., a report might be longer simply due to the complexity of the business the firm operates in, as indicated in \textcite{LM-meta-2016}); in this context, there would be no incentive to disguise information by verbose language, thereby breaking the significance of the obfuscation theory. Therefore, I hypothesize that the first effect dominates and more (less) readable 10-K*s will induce lower (higher) \texttt{PFRV}.

In terms of measurement of length and readability, I follow \textcite{Loughran2014}, who suggest the (logarithm of) gross file size of the filing document as a potent proxy for readability, which at the same time allows to easily circumvent the issues arising from measures that are influenced by the parsing procedure applied by the researcher. 

\cbox[light_gray]{H7: The management's focus on financial topics (denoted by \texttt{FIN}) is associated with lower \texttt{PFRV}.}

This hypothesis is motivated by \textcite[1-2]{Amel-Zadeh_Faasse_2016} who state that \enquote{if information is abstract and heavily loaded with statistical and quantitative data, people tend to underweight it in their decision making}. Following this notion, embedding qualitative information in a glut of financial figures, ratios, and percentages will engender that market participants perceive this content as less informative, thereby reducing the relevance of the textual part and leading to lower \texttt{PFRV}.

Similarly to \textcite{HuangZangZheng14}, I will measure \texttt{FIN} as a function of the number of appearances of financial symbols. In fact, in the cleaning process of the corpus, I convert symbols to their corresponding word equivalents (e.g., \textsf{\%} becomes \textsf{percent}, \textsf{\$} becomes \textsf{dollar}, and so on). I then construct the \texttt{FIN} variable as the log of one plus the sum of the term frequencies for the following words: \textsf{percent}, \textsf{dollar}, \textsf{euro}, \textsf{yen}, \textsf{pound}, and \textsf{franc} (thereby covering occurrences of most commonly used currencies that could potentially arise within a filing). 

% ----------------------------------------------------------- %

\subsection{Control Variables}
\label{ssec: volamodel_controls}
In order to control for other potential factors that influence \texttt{PFRV}, I consider some additional independent variables that have been shown to be successful predictors of volatility: 

\begin{enumerate}[(1)]

\item \texttt{SIZE}: natural logarithm of total assets at the fiscal year-end preceding the 10-K* filing year. Smaller firms are considered more risky due to the fact that their assets and projects are relatively undiversified \parencite{KothariLiShort_2009}. 

\item\texttt{BTM}: natural logarithm of the book-to-market ratio at the fiscal year-end preceding the 10-K* filing year. Firms with higher book-to-market ratios are on average expected to be more risky, as market participants assign lower market valuation (denominator) to companies if they perceive their future cash flows to be rather uncertain \parencite{KothariLiShort_2009}. 

\item \texttt{TRVOL}: natural logarithm of the median stock trading volume (number of shares that have been traded) in the business week (i.e., five days) preceding the 10-K* filing date. This is motivated by model specifications in \textcite{AntweilerFrank2004} as well as \textcite{Tetlock2007}, who on the basis of findings in \textcite{JonesKaulLipson_1994} include trading volume as predictor for stock volatility. The latter evidence that the positive relationship between volume and volatility is driven by the sheer frequency of transactions (i.e., the number of shares traded generates volatility, regardless of the \textit{size} of the transaction). 

\item \texttt{VIX}: median level of the CBOE VIX in the business week (i.e., five days) preceding the 10-K* filing date. This variable is included as a measure for market-wide volatility and serves to better isolate the \enquote{idiosyncratic} part of firm-level volatility. 

\item \texttt{LEVER}: financial leverage (i.e., total liabilities divided by total assets) at the fiscal year-end preceding the 10-K* filing year. More levered companies are perceived as more risky by market participants, therefore being related to higher stock return volatility \parencite{KothariLiShort_2009}.

\item \texttt{YRDUMMY}: 18 dummy variables indicating the year in which the 10-K* was filed. This variable is included to control for annual trends.

\item \texttt{MTHDUMMY}: eleven dummy variables indicating the month in which the 10-K* was filed. This variable is included to control for seasonality and/or other market anomalies within a calendar year (e.g., turn-of-the-year / \enquote{January} effect).

\item \texttt{WEEKDAYDUMMY}: four dummy variables indicating the weekday on which the 10-K* was filed. This variable is included to control for weekday effects as well as to account for potential disruptions of business weeks due to weekends. 

\item \texttt{MONTHDAYDUMMY}: 30 dummy variables indicating the day of the month on which the 10-K* was filed. This variable is included to control for \enquote{turn of the month} effect. 

\item \texttt{SECTORDUMMY}: 65 dummy variables indicating the first two digits of the SIC code of the filing company. This variable is included as a measure for industry differences.

\item \texttt{10KDUMMY}: 12 dummy variables indicating the 10-K filing type. This variable is included so as to account for potential different volatility responses due to the nature and type of the filing; for instance, the explanatory power of text in an amended 10-K might be different from a \enquote{regular} 10-K. 

\end{enumerate}

% ----------------------------------------------------------- %

\subsection{Bringing Everything Together: Model Specification}
\label{ssec: volamodel_models}
Using the definition of \texttt{PFRV} from section \ref{ssec: senti_LHS} (equation \eqref{eq: pfrv-definition}) and combining it with the sentiment scores calculated using equation \eqref{eq: vib-regression} presented in section \ref{ssec: senti_termweighting} as well as the control variables (section \ref{ssec: volamodel_controls}), I aim to test the hypotheses expressed in section \ref{ssec: volamodel_vola+senti} with a linear model specification, which will be explained in this subsection. 

For illustrative purposes, Figure \ref{fig: res_design} additionally describes the research design in graphical manner. As is indicated in the legend, the orange area with diagonal pattern represents three years of rolling training data which is used to estimate the regression in equation \eqref{eq: vib-regression}. The green dots represent the filing dates; the green area with horizontal pattern represents the post-filing time horizon - it is set equal to $[t, t+4]$ days for filings submitted in $t$ so as to measure weekly volatility. The blue area with vertical pattern represents a varying time window that is used to construct independent variables, where applicable (for instance, for \texttt{PreFRV}, \texttt{TRVOL} and \texttt{VIX} it will be five days).

\subsubsection{Linear Regression Model}
\label{sssec: volamodel_models_linreg}
\nomenclature{MZ Regression}{Mincer-Zarnowitz Regression}
The multivariate model attempts to describe post-filing realized volatility as a linear combination of different explanatory variables in a classical regression framework. As all independent variables are known at the respective filing date, this model can actually be interpreted as a forecasting exercise. Moreover, as \texttt{PFRV} was modelled using a fixed post-filing time window, the linear model described below applies to the \textit{cross section} of out-of-sample annual filings.

Analytically, the linear model can be described as follows:
\begin{align*} \label{eq: linear_reg}
\texttt{PFRV}  = & \beta_0 + \beta_1 \texttt{PreFRV} + \beta_2 \texttt{NEG\_SENT} + \beta_3 \texttt{POS\_SENT}  + \beta_4 \texttt{ASSERT} + \beta_5 \texttt{UNCERT} + \beta_6 \texttt{LITI} + \\ & 
\beta_7 \texttt{GFS} + \beta_8 \texttt{FIN} + \beta_9 \texttt{SIZE} + \beta_{10} \texttt{BTM} + \beta_{11} \texttt{TRVOL} + \beta_{12} \texttt{VIX} + \beta_{13} \texttt{LEVER} + \\ & 
\sum_{l = 14}^{31} \beta_{l} \texttt{YRDUMMY}_l + \sum_{l = 32}^{42} \beta_{l} \texttt{MTHDUMMY}_l + \sum_{l = 43}^{46} \beta_{l} \texttt{WEEKDAYDUMMY}_l + \\ &  
\sum_{l = 47}^{76} \beta_{l} \texttt{MONTHDAYDUMMY}_l + \sum_{l = 77}^{141} \beta_{l} \texttt{SECTORDUMMY}_l + \sum_{l = 142}^{153} \beta_{l} \texttt{10KDUMMY}_l + e \numberthis
\end{align*}
For the sake of readability, document ($i$) and date ($t$) indices are suppressed. Equation \eqref{eq: linear_reg} will be estimated via OLS for all out-of-sample 10-K*s. The sample split into training and test set will cover three variants: a static, rolling, and extending training window. Details regarding the size of training and test set will be outlined in the next section, \ref{sssec: volamodel_N1_N2}. Moreover, applying common hat notation to denote sample estimates for the coefficients in equation \eqref{eq: linear_reg}, with respect to the hypotheses presented above, I expect $\hat{\beta_2}$, $\hat{\beta_5}$, $\hat{\beta_6}$, and $\hat{\beta_7}$ to be positive and $\hat{\beta_4}$, and $\hat{\beta_8}$ to be negative. $\hat{\beta_3}$ is expected to be different from zero, with no prediction on the sign. 

Referring to time-series practice, regressing \enquote{actual} values of volatility (proxied by realized volatility) against forecasted values of volatility is a common method to evaluate forecasting accuracy and is referred to as Mincer-Zarnowitz-Regression (henceforth MZ-regression). In the framework of this thesis, the univariate MZ-regression reads $\texttt{PFRV}  = \beta_0 + \beta_1 \mathtt{PreFRV} + e$. The \enquote{suitability} of the basic \enquote{auto-regressive} model in volatility would then be evaluated by a joint test of $\text{H0: } \beta_0 = 0 \land \beta_1 = 1$ versus $\text{H1: } \beta_0 \neq 0 \lor \beta_1 \neq 1$ \parencite[337]{Diebold_Book_2017}. Of course, the MZ testing procedure can be applied for any sort of forecast and is not restricted to the basic case of using pre-filing volatility to explain post-filing volatility; in fact, in more sophisticated predictors from the GARCH-model family will be considered in robustness checks to the specification just presented (cf. section \ref{ssec: robust_prefiling}). 

Extending the concept of the MZ-regression, equation \eqref{eq: linear_reg} can be seen as an \enquote{augmented MZ-regression}, whose main function is to provide evidence on whether textual variables extracted from corporate 10-K* filings can explain post-filing realized volatility for a given firm in the cross section, after controlling for other common factors that have shown to influence stock return volatility. In terms of forecast evaluation, a \textbf{fully} capable quantitative model would imply that all beta coefficients in equation \eqref{eq: linear_reg}, with the exception of $\beta_1$, are zero \parencite{PattonSheppard2009, ViolanteLaurent2012}, whereas in this work I will be moreover interested in the significance of the other non-zero coefficients, and especially coefficients of those variables that relate to the textual part of the 10-K* filing. 

\subsubsection{Choice of Training and Test Set}
\label{sssec: volamodel_N1_N2}
Summarizing briefly,  the research framework of this thesis bases upon \texttt{VIBTW}, which in turn grounds on three basic steps:

\begin{enumerate}
\item Estimating \texttt{VIBTW}-weights $\hat{w}_{j}$ for each word $j$ in LM lexicon $k$ using equations \eqref{eq: vib-regression} and \eqref{eq: wv_estimates}. This linear regression is estimated by OLS using the \textit{training} sample, $N1$.
\item Applying the learned term weights $\hat{w}_{j}$ to term frequencies that are \textbf{outside} of the training sample, which involves multiplying them with relative term frequencies from 10-K*s in the testing sample ($N_2$). After this transformation, \texttt{VIBTW}-weighted term frequencies are aggregated into a sentiment score for category $k$ (using equation \eqref{eq: vibtw_score}). 
\item Using sentiment scores from out-of-sample 10-K*s to fit an augmented MZ-regression (equation \eqref{eq: linear_reg}), which attempts to explain \texttt{PFRV}. This regression is estimated using the test set, $N_2$. 
\end{enumerate}

Thus, one needs to split the sample in such manner that a fraction $N_1$ is used for weight estimation and the remaining fraction ($N_2$) is used for score calculation and MZ-regressions\footnote{Note that the sample split is not exclusive to \texttt{VIBTW}; it also required for calculating inverse-document-frequencies.}.
Regarding the choice of $N_1$ and $N_2$, three alternative specifications will be tested in this thesis: 

\begin{enumerate}
\item Static Window: the training window will be the same for each of the five out-of-sample years ranging from 2013-2017, implying that $N_1$ will encompass all 10-K*s from 1999 up to (including) 2012\footnote{The choice to set the training window to 14 years, i.e., about 75 percent of the whole sample, is motivated by two reasons: firstly, although the choice is still arbitrary, many applications adopt a full sample split of 70 versus 30 or 80 versus 20 percent; secondly, the 14-year subset is large enough to avoid singularity and collinearity problems in estimating equation \eqref{eq: vib-regression} and yet leave a large enough test sample to be able to fit the regressor-rich model in equation \eqref{eq: linear_reg}.}.
\item Rolling Window: the natural extension to a static 14-year in-sample period is to make that subset roll along for each year in the test set. For instance, \texttt{VIBTW}-sentiment scores in equation \eqref{eq: linear_reg} for out-of-sample year 2013 will be based on weights derived from all filings from 1999 to 2012; whereas for 2014 they will be derived from 2000-2013; for 2015 they will be derived from 2001-2014; and so on. 
\item Extending Window: another alternative is to fix the starting point of the training set but let the ending point roll along, thereby making the in-sample window grow. As a consequence, for each year in the test set, all available information prior to the filing year is used to estimate \texttt{VIBTW}-weights. Thus, for 2013 the training window will (equivalently to methods 1 and 2 above) be 1999-2012, while for 2014 it will be 1999-2013, for 2015 it will be 1999-2014, etc. 
\end{enumerate}

\clearpage